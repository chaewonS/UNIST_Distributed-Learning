{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zEjpMt12CMZ"
   },
   "source": [
    "# Project 2: Implementing FL algorithms [100 pts]\n",
    "In this project, you have to implement some FL algorithms and the dirichlet distribution based non-iid partition that you learned in the class. Please refer to the paepers below. Be sure to **store** the intermediate outputs generated while running the cells. Although we will rerun the code to evaluate your final score in top-down fashion, missing outputs may lead to grade reductions.\n",
    "\n",
    "Please submit your iPython file named as follows: `'Project2_AIGS_(student_ID)_(your name).ipynb'`. For example, `Project2_AIGS_20220000_Gildong_Hong.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8wFtUA3TJn6"
   },
   "source": [
    "### Library Imports  \n",
    "You can import any additional libraries here, but **DO NOT** include external libraries that have a direct implementation FL algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjHMDl1NDb-W"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "\n",
    "# import additional libraries here if necessary.\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    #random.seed(seed)\n",
    "seed_everything(42)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StkzaerXS-Fi"
   },
   "source": [
    "## Problem 1. Dirichlet distribution based Non-IID partition (20 pt.)\n",
    "\n",
    "Complete the skeleton code according to the comments.\n",
    "\n",
    "(1) Generate Dirichlet distribution probabilities\n",
    "\n",
    "(2) Split indices based on Dirichlet probabilities, Ensure all indices are used\n",
    "\n",
    "(3) Using .extend function, compose each user's data into user_indices[user_id]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2D5piDcFR_hB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "User 0: 7353 samples, Label distribution: [ 268  382    0 1124  548  127 1063 2719  352  770]\n",
      "User 1: 5134 samples, Label distribution: [1262   83   47   82 1303   39    0   31  428 1859]\n",
      "User 2: 1472 samples, Label distribution: [ 46 202  69  20  12  63 183 756  90  31]\n",
      "User 3: 4310 samples, Label distribution: [   6   38  214    5  634 1666   15   84 1636   12]\n",
      "User 4: 8386 samples, Label distribution: [ 719  375 2567  836  666  326 2643  202   52    0]\n",
      "User 5: 4744 samples, Label distribution: [   0    4 1722    0  230  711  283  643  786  365]\n",
      "User 6: 8417 samples, Label distribution: [2097 3290  263  616    0 1223  139   12  220  557]\n",
      "User 7: 2858 samples, Label distribution: [ 63  90   5 832   0 725 260 154   6 723]\n",
      "User 8: 4108 samples, Label distribution: [ 177  518    1 1380   83   76  409    2 1335  127]\n",
      "User 9: 3218 samples, Label distribution: [ 362   18  112  105 1524   44    5  397   95  556]\n"
     ]
    }
   ],
   "source": [
    "def split_data_iid(dataset: Dataset, num_users: int) -> List[Subset]:\n",
    "    num_items = len(dataset) // num_users\n",
    "    indices = np.random.permutation(len(dataset))\n",
    "    return [Subset(dataset, indices[i * num_items:(i + 1) * num_items]) for i in range(num_users)]\n",
    "\n",
    "def split_data_non_iid(dataset: Dataset, num_users: int, alpha: float) -> List[Subset]:\n",
    "    \"\"\"Split dataset into Non-IID subsets for each user using Dirichlet distribution.\"\"\"\n",
    "    num_classes = len(dataset.classes)\n",
    "    class_indices = defaultdict(list)\n",
    "\n",
    "    # Group indices by class\n",
    "    for idx, (_, label) in enumerate(dataset):\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    # Ensure each class is represented by its indices\n",
    "    class_indices = {k: np.array(v) for k, v in class_indices.items()}\n",
    "\n",
    "    # (1) Generate Dirichlet distribution probabilities\n",
    "    dirichlet_dist = np.random.dirichlet([alpha] * num_users, num_classes) # Implement here!\n",
    "\n",
    "    user_indices = [[] for _ in range(num_users)]\n",
    "    for class_id, probabilities in enumerate(dirichlet_dist):\n",
    "        class_idx = class_indices[class_id]\n",
    "        np.random.shuffle(class_idx)  # Shuffle class indices\n",
    "\n",
    "        # (2) Split indices based on Dirichlet probabilities, Ensure all indices are used\n",
    "        split = (probabilities * len(class_idx)).astype(int) # Implement here! \n",
    "        split[-1] = len(class_idx) - np.sum(split[:-1]) # Implement here! \n",
    "\n",
    "        # (3) Using .extend function, compose each user's data into user_indices[user_id].\n",
    "        # Implement here!\n",
    "        start = 0\n",
    "        for user_id, size in enumerate(split): \n",
    "            end = start + size\n",
    "            user_indices[user_id].extend(class_idx[start:end]) \n",
    "            start = end\n",
    "\n",
    "\n",
    "    # Create Subsets for each user\n",
    "    return [Subset(dataset, indices) for indices in user_indices]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "cifar10_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "cifar10_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = DataLoader(cifar10_test, batch_size=128, shuffle=False)\n",
    "\n",
    "non_iid_data = split_data_non_iid(cifar10_train, 10, 0.5)\n",
    "for i, user_data in enumerate(non_iid_data):\n",
    "    labels = [cifar10_train[idx][1] for idx in user_data.indices]\n",
    "    print(f\"User {i}: {len(user_data)} samples, Label distribution: {np.bincount(labels, minlength=10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2~4. FL Algorithms\n",
    "\n",
    "Please implement each algorithm by referring to the papers presented below. \n",
    "\n",
    "And explain those algorithms, including the formula. **Write it short, focusing on the differences from FedAvg.**\n",
    "\n",
    "Reach the highest performance in a given federated learning situation. **You can freely set up hyperparameters.**\n",
    "\n",
    "Even if your performances are not too high, we will also consider the completeness of your code when we grade your project.\n",
    "\n",
    "\n",
    "1. **FedAvgM** (25 pt.) -> You only need to modify the Server class.\n",
    "2. **FedProx** (25 pt.) -> You only need to modify the User class.\n",
    "3. **SCAFFOLD** (30 pt.) -> Use the given variables to implement if you want. There are no restrictions on code modification when implementing this algorithm.\n",
    "\n",
    "**Paper List**\n",
    "\n",
    "[1] FedAvgM - https://arxiv.org/abs/1909.06335\n",
    "\n",
    "[2] FedProx - https://arxiv.org/pdf/1812.06127\n",
    "\n",
    "[3] SCAFFOLD - https://arxiv.org/pdf/1910.06378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FedAvgM (Explanation 10 pt. Code 15 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerFedAvgM:\n",
    "    def __init__(self, model: nn.Module, users: List[User], momentum: float = 0.9, lr: float = 1.0):\n",
    "        self.global_model = model\n",
    "        self.users = users\n",
    "        self.momentum = momentum\n",
    "        self.lr = lr\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.global_model.to(self.device)\n",
    "\n",
    "        self.momentum_buffer = {name: torch.zeros_like(param) for name, param in self.global_model.state_dict().items()}\n",
    "\n",
    "    def aggregate(self, updates: List[Dict[str, torch.Tensor]]):\n",
    "        avg_update = {name: torch.zeros_like(param) for name, param in updates[0].items()}\n",
    "\n",
    "        for update in updates:\n",
    "            for name, param in update.items():\n",
    "                avg_update[name] += param / len(updates)\n",
    "\n",
    "        for name in avg_update.keys():\n",
    "            self.momentum_buffer[name] = (\n",
    "                self.momentum * self.momentum_buffer[name] + avg_update[name]\n",
    "            )\n",
    "            avg_update[name] = self.momentum_buffer[name]\n",
    "\n",
    "        for name, param in self.global_model.state_dict().items():\n",
    "            param -= self.lr * avg_update[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explain the FedAvgM algorithm here.)\n",
    "\n",
    "## FedAvgM (Federated Averaging with Momentum)\n",
    "\n",
    "FedAvgM extends the FedAvg algorithm by incorporating momentum into the global model updates. This helps smooth the updates and improves convergence speed and stability by considering the history of updates.\n",
    "\n",
    "### Update Formula:\n",
    "\n",
    "$m_{t+1} = \\beta \\cdot m_t + \\frac{1}{K} \\sum_{k=1}^{K} g_k^t$\n",
    "\n",
    "Where:\n",
    "- $m_t$: Momentum buffer at round $t$\n",
    "- $\\beta$: Momentum coefficient\n",
    "- $g_k^t$: Local update from client $k$\n",
    "- $K$: Number of selected clients\n",
    "\n",
    "The global model is updated as: $w_{t+1} = w_t - \\eta \\cdot m_{t+1}$\n",
    "\n",
    "Where:\n",
    "- $\\eta$: Learning rate\n",
    "\n",
    "### Key Differences from FedAvg:\n",
    "\n",
    "1. **Momentum Buffer**: FedAvgM introduces a momentum buffer $m_t$ that accumulates past gradients, allowing the algorithm to maintain a \"velocity\" in parameter space.\n",
    "\n",
    "2. **Update Smoothing**: The momentum term $\\beta \\cdot m_t$ helps smooth out oscillations in the optimization trajectory, potentially leading to faster convergence.\n",
    "\n",
    "3. **Historical Information**: By incorporating information from previous rounds, FedAvgM can overcome local optima and saddle points more effectively than FedAvg.\n",
    "\n",
    "4. **Adaptive Step Sizes**: The effective step size in parameter space can be larger for dimensions with consistent gradients across rounds, accelerating progress in those directions.\n",
    "\n",
    "5. **Hyperparameter Sensitivity**: FedAvgM introduces an additional hyperparameter $\\beta$ (momentum coefficient), which requires tuning but can lead to improved performance when set correctly.\n",
    "\n",
    "6. **Computational Overhead**: FedAvgM requires maintaining and updating the momentum buffer, slightly increasing the computational and memory requirements compared to FedAvg.\n",
    "\n",
    "These differences allow FedAvgM to potentially achieve better convergence and generalization performance, especially in scenarios with non-IID data distributions or when dealing with complex optimization landscapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FedProx (Explanation 10 pt. Code 15 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserFedProx:\n",
    "    def __init__(self, user_id: int, model: nn.Module, data: Dataset, lr: float, mu: float):\n",
    "        self.user_id = user_id\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.mu = mu\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self, global_model: nn.Module, epochs: int):\n",
    "        self.model.train()\n",
    "        global_params = {name: param.clone().detach() for name, param in global_model.state_dict().items()}\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        train_loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                prox_term = 0.5 * self.mu * sum(\n",
    "                    torch.norm(param - global_params[name]) ** 2\n",
    "                    for name, param in self.model.state_dict().items()\n",
    "                )\n",
    "                loss += prox_term\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (len(train_loader) * epochs)\n",
    "        return self.model.state_dict(), avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explain the FedProx algorithm here.)\n",
    "\n",
    "## FedProx (Federated Proximal)\n",
    "\n",
    "FedProx is an extension of the FedAvg algorithm that adds a proximity term to the local loss function. This term penalizes the divergence of local models from the global model, ensuring stability in non-IID data scenarios.\n",
    "\n",
    "### Loss Function:\n",
    "\n",
    "$L_{\\text{FedProx}} = L_{\\text{CE}} + \\frac{\\mu}{2} \\sum_{i} | w_i - w_{t,i} |^2$\n",
    "\n",
    "Where:\n",
    "- $L_{\\text{CE}}$: Cross-entropy loss\n",
    "- $w_t$: Global model parameters at round $t$\n",
    "- $w$: Local model parameters\n",
    "- $\\mu$: Proximity term coefficient\n",
    "\n",
    "### Key Differences from FedAvg:\n",
    "\n",
    "1. **Proximity Term**: FedProx introduces a regularization term $\\frac{\\mu}{2} \\sum_{i} | w_i - w_{t,i} |^2$ that penalizes large deviations of local model parameters from the global model parameters. This helps maintain consistency across clients.\n",
    "\n",
    "2. **Handling Non-IID Data**: The proximity term stabilizes training in non-IID data settings by discouraging local models from straying too far from the global model, addressing one of the main challenges in federated learning.\n",
    "\n",
    "3. **Regularization Effect**: The added penalty acts as a form of regularization, which can improve generalization by preventing overfitting to local data distributions.\n",
    "\n",
    "4. **Hyperparameter $\\mu$**: The proximity term introduces a new hyperparameter $\\mu$, which controls the strength of the regularization. Proper tuning of this parameter is crucial for balancing convergence speed and stability.\n",
    "\n",
    "5. **Local Training Dynamics**: Unlike FedAvg, where local updates can diverge significantly, FedProx ensures that updates are more aligned with the global objective, potentially leading to more stable and faster convergence.\n",
    "\n",
    "These differences make FedProx particularly suitable for federated learning scenarios where data heterogeneity is a significant concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCAFFOLD (Explanation 15 pt. Code 15 pt.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserScaffold:\n",
    "    def __init__(self, user_id: int, model: nn.Module, data: Dataset, lr: float):\n",
    "        self.user_id = user_id\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        self.local_control = {name: torch.zeros_like(param) for name, param in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model: nn.Module, global_control: Dict[str, torch.Tensor], epochs: int):\n",
    "        self.model.train()\n",
    "        global_params = {name: param.clone().detach() for name, param in global_model.state_dict().items()}\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        train_loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "\n",
    "                # Adjust gradients using control variates\n",
    "                for name, param in self.model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        param.grad += self.local_control[name] - global_control[name]\n",
    "                \n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        delta_control = {\n",
    "            name: global_control[name] - self.local_control[name]\n",
    "            for name in self.local_control.keys()\n",
    "        }\n",
    "        self.local_control = delta_control\n",
    "\n",
    "        avg_loss = total_loss / (len(train_loader) * epochs)\n",
    "        return self.model.state_dict(), delta_control, avg_loss\n",
    "\n",
    "class ServerScaffold:\n",
    "    def __init__(self, model: nn.Module, users: List[User]):\n",
    "        self.global_model = model\n",
    "        self.users = users\n",
    "        self.global_control = {name: torch.zeros_like(param) for name, param in self.global_model.state_dict().items()}\n",
    "\n",
    "    def aggregate(self, updates: List[Dict[str, torch.Tensor]], delta_controls: List[Dict[str, torch.Tensor]]):\n",
    "        avg_update = {name: torch.zeros_like(param) for name, param in updates[0].items()}\n",
    "        for update in updates:\n",
    "            for name, param in update.items():\n",
    "                avg_update[name] += param / len(updates)\n",
    "\n",
    "        for name, param in self.global_model.state_dict().items():\n",
    "            param.data += avg_update[name]\n",
    "\n",
    "        avg_delta_control = {name: torch.zeros_like(param) for name, param in delta_controls[0].items()}\n",
    "        for delta_control in delta_controls:\n",
    "            for name, param in delta_control.items():\n",
    "                avg_delta_control[name] += param / len(delta_controls)\n",
    "        for name in self.global_control.keys():\n",
    "            self.global_control[name] += avg_delta_control[name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Explain the SCAFFOLD algorithm here.)\n",
    "\n",
    "## SCAFFOLD (Stochastic Controlled Averaging for Federated Learning)\n",
    "\n",
    "SCAFFOLD mitigates the effect of client drift in non-IID data by introducing control variates. These variates adjust local updates, reducing the variance caused by differences in client data distributions.\n",
    "\n",
    "### Local Update Formula:\n",
    "\n",
    "$w_k^{t+1} = w_k^t - \\eta \\cdot \\left( \\nabla L + c_k - c \\right)$\n",
    "\n",
    "Where:\n",
    "- $c_k$: Local control variate for client $k$\n",
    "- $c$: Global control variate\n",
    "- $\\nabla L$: Gradient of the loss function\n",
    "- $\\eta$: Learning rate\n",
    "\n",
    "### Global Update Formula:\n",
    "\n",
    "$c^{t+1} = c^t + \\frac{1}{K} \\sum_{k=1}^{K} \\left( c_k - c^t \\right)$\n",
    "\n",
    "Where:\n",
    "- $K$: Number of selected clients\n",
    "\n",
    "### Key Differences from FedAvg:\n",
    "\n",
    "1. **Control Variates**: SCAFFOLD introduces local and global control variates ($c_k$ and $c$) to adjust the gradients during local training. This helps align local updates more closely with the global objective.\n",
    "\n",
    "2. **Variance Reduction**: By using control variates, SCAFFOLD reduces the variance in updates caused by non-IID data distributions, leading to more stable and consistent convergence.\n",
    "\n",
    "3. **Mitigating Client Drift**: The use of control variates helps mitigate client drift, a common issue in federated learning where local models diverge significantly from the global model due to data heterogeneity.\n",
    "\n",
    "4. **Convergence Speed**: SCAFFOLD can achieve faster convergence compared to FedAvg by ensuring that updates are better aligned with the global model, reducing the need for frequent communication rounds.\n",
    "\n",
    "5. **Additional Overhead**: The algorithm requires maintaining and updating control variates, which introduces additional computational and memory overhead compared to FedAvg.\n",
    "\n",
    "These differences make SCAFFOLD particularly effective in federated learning scenarios with highly non-IID data distributions, where traditional methods like FedAvg struggle to maintain model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "p3Hu8doDcSDC"
   },
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, user_id: int, model: nn.Module, data: Dataset, lr: float, method: str, mu: float):\n",
    "        self.user_id = user_id\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.lr = lr\n",
    "        self.method = method\n",
    "        self.mu = mu\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.c_local = {name: torch.zeros_like(param) for name, param in self.model.state_dict().items()}\n",
    "\n",
    "    def train(self, global_model: nn.Module, epochs: int, global_control: Dict[str, torch.Tensor] = {\"None\": torch.Tensor(0)}):\n",
    "        \"\"\"Train the local model.\"\"\"\n",
    "        self.model.load_state_dict(global_model.state_dict())\n",
    "        self.model.train()\n",
    "        global_params = {name: param.clone().detach() for name, param in global_model.state_dict().items()}\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        train_loader = DataLoader(self.data, batch_size=32, shuffle=True)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        # You can use this variable to implement SCAFFOLD.\n",
    "        delta_c_local = {name: torch.zeros_like(param) for name, param in self.c_local.items()}\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # (2) FedProx\n",
    "                if self.method == 'FedProx':\n",
    "                    prox_term = 0.5 * self.mu * sum(\n",
    "                        torch.norm(param - global_params[name]) ** 2\n",
    "                        for name, param in self.model.state_dict().items()\n",
    "                    )\n",
    "                    loss += prox_term\n",
    "\n",
    "\n",
    "                # (3)SCAFFOLD\n",
    "                elif self.method == 'SCAFFOLD':\n",
    "                    for name, param in self.model.named_parameters():\n",
    "                        if param.grad is not None:\n",
    "                            param.grad += self.c_local[name] - global_control[name]\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        # Update delta_c_local for SCAFFOLD\n",
    "        if self.method == 'SCAFFOLD':\n",
    "            for name in delta_c_local.keys():\n",
    "                delta_c_local[name] = global_control[name] - self.c_local[name]\n",
    "                self.c_local[name] += delta_c_local[name]\n",
    "                \n",
    "        avg_loss = total_loss / (len(train_loader) * epochs)\n",
    "        \n",
    "        return self.model.state_dict(), delta_c_local, avg_loss\n",
    "\n",
    "# Define the Server class\n",
    "class Server:\n",
    "    def __init__(self, model: nn.Module, users: List[User], method: str, momentum: float):\n",
    "        self.global_model = model\n",
    "        self.users = users\n",
    "        self.method = method\n",
    "        self.momentum = momentum\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.global_model.to(self.device)\n",
    "\n",
    "        # FedAvgM momentum state\n",
    "        self.momentum_buffer = {name: torch.zeros_like(param) for name, param in self.global_model.state_dict().items()}\n",
    "\n",
    "        # SCAFFOLD c_global\n",
    "        self.c_global = {name: torch.zeros_like(param) for name, param in self.global_model.state_dict().items()}\n",
    "\n",
    "\n",
    "    def select_users(self, fraction: float):\n",
    "        num_selected = max(1, int(fraction * len(self.users)))\n",
    "        return np.random.choice(self.users, num_selected, replace=False)\n",
    "\n",
    "    def aggregate(self, updates: List[Dict[str, torch.Tensor]], delta_cs: List[Dict[str, torch.Tensor]] = [{\"None\": torch.Tensor(0)}]):\n",
    "\n",
    "        avg_update = {name: torch.zeros_like(param) for name, param in updates[0].items()}\n",
    "\n",
    "        if self.method in ['FedAvg', 'FedAvgM']:\n",
    "            for update in updates:\n",
    "                for name, param in update.items():\n",
    "                    avg_update[name] += param / len(updates)\n",
    "\n",
    "            # (1) FedAvgM\n",
    "            if self.method == 'FedAvgM':\n",
    "                for name in avg_update.keys():\n",
    "                    self.momentum_buffer[name] = (\n",
    "                        self.momentum * self.momentum_buffer[name] + avg_update[name]\n",
    "                    )\n",
    "                    avg_update[name] = self.momentum_buffer[name]\n",
    "            \n",
    "                for name, param in self.global_model.state_dict().items():\n",
    "                    param.data -= self.momentum_buffer[name]\n",
    "                \n",
    "            self.global_model.load_state_dict(avg_update)\n",
    "\n",
    "        elif self.method == 'FedProx':\n",
    "            # FedProx uses FedAvg-style aggregation\n",
    "            for update in updates:\n",
    "                for name, param in update.items():\n",
    "                    avg_update[name] += param / len(updates)\n",
    "            self.global_model.load_state_dict(avg_update)\n",
    "\n",
    "        elif self.method == 'SCAFFOLD':\n",
    "            for update in updates:\n",
    "                for name, param in update.items():\n",
    "                    avg_update[name] += param / len(updates)\n",
    "\n",
    "            self.global_model.load_state_dict(avg_update)\n",
    "\n",
    "            # Update c_global for SCAFFOLD\n",
    "            if self.method == 'SCAFFOLD' and delta_cs is not None:\n",
    "                # (3-3) Implement SCAFFOLD.\n",
    "                avg_delta_c = {name: torch.zeros_like(param) for name, param in delta_cs[0].items()}\n",
    "                for delta_c in delta_cs:\n",
    "                    for name, param in delta_c.items():\n",
    "                        avg_delta_c[name] += param / len(delta_cs)\n",
    "            \n",
    "                for name in self.c_global.keys():\n",
    "                    self.c_global[name] += avg_delta_c[name]\n",
    "\n",
    "    def evaluate(self, test_loader: DataLoader):\n",
    "        self.global_model.eval()\n",
    "        correct, total = 0, 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.global_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        avg_loss = total_loss / len(test_loader)\n",
    "        return accuracy, avg_loss\n",
    "\n",
    "\n",
    "def federated_learning(\n",
    "    server: Server, rounds: int, epochs: int, fraction: float, test_loader: DataLoader\n",
    "):\n",
    "    for round_num in range(rounds):\n",
    "        print(f\"Round {round_num + 1}/{rounds} starting...\")\n",
    "        selected_users = server.select_users(fraction)\n",
    "        updates = []\n",
    "        delta_cs = []  # For SCAFFOLD\n",
    "\n",
    "        local_losses = []\n",
    "        for user in selected_users:\n",
    "            if server.method == 'SCAFFOLD':\n",
    "                local_update, delta_c, local_loss = user.train(server.global_model, epochs, server.c_global)\n",
    "                delta_cs.append(delta_c)\n",
    "            else:\n",
    "                local_update, _, local_loss = user.train(server.global_model, epochs)\n",
    "            updates.append(local_update)\n",
    "            local_losses.append(local_loss)\n",
    "\n",
    "        avg_local_loss = sum(local_losses) / len(local_losses)\n",
    "\n",
    "        if server.method == 'SCAFFOLD':\n",
    "            server.aggregate(updates, delta_cs)\n",
    "        else:\n",
    "            server.aggregate(updates)\n",
    "        accuracy, global_loss = server.evaluate(test_loader)\n",
    "        print(f\"Round {round_num + 1}/{rounds} completed.\")\n",
    "        print(f\" Avg Local Loss: {avg_local_loss:.4f}\")\n",
    "        print(f\" Global Loss: {global_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "def federated_learning_with_scenario(\n",
    "    server_class,\n",
    "    user_class,\n",
    "    global_model_class,\n",
    "    dataset: Dataset,\n",
    "    num_users: int,\n",
    "    rounds: int,\n",
    "    epochs: int,\n",
    "    fraction: float,\n",
    "    iid: bool,\n",
    "    lr: float,\n",
    "    alpha: float,\n",
    "    test_loader: DataLoader,\n",
    "    momentum: float,\n",
    "    method: str,\n",
    "    mu: float,\n",
    "):\n",
    "\n",
    "    if iid:\n",
    "        user_data = split_data_iid(dataset, num_users)\n",
    "        print(f\"Data split: IID with {num_users} users.\")\n",
    "    else:\n",
    "        user_data = split_data_non_iid(dataset, num_users, alpha)\n",
    "        print(f\"Data split: Non-IID with {num_users} users (alpha={alpha}).\")\n",
    "\n",
    "    users = [\n",
    "        user_class(user_id=i, model=global_model_class(), data=user_data[i], lr=lr, method=method, mu=mu)\n",
    "        for i in range(num_users)\n",
    "    ]\n",
    "\n",
    "    global_model = global_model_class()\n",
    "    server = server_class(model=global_model, users=users, method=method, momentum=momentum)\n",
    "\n",
    "    federated_learning(server, rounds, epochs, fraction, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IG6jd3RDcfVc",
    "outputId": "c6196e8f-a628-4dcc-db85-aeaa4fb897af"
   },
   "outputs": [],
   "source": [
    "num_users = 20\n",
    "fraction = 0.4\n",
    "rounds = 200\n",
    "iid = False\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: Non-IID with 20 users (alpha=0.5).\n",
      "Round 1/200 starting...\n",
      "Round 1/200 completed.\n",
      " Avg Local Loss: 2.2681\n",
      " Global Loss: 2.3048, Accuracy: 10.00%\n",
      "Round 2/200 starting...\n",
      "Round 2/200 completed.\n",
      " Avg Local Loss: 2.2799\n",
      " Global Loss: 2.3028, Accuracy: 10.91%\n",
      "Round 3/200 starting...\n",
      "Round 3/200 completed.\n",
      " Avg Local Loss: 2.2685\n",
      " Global Loss: 2.3013, Accuracy: 13.13%\n",
      "Round 4/200 starting...\n",
      "Round 4/200 completed.\n",
      " Avg Local Loss: 2.2730\n",
      " Global Loss: 2.2995, Accuracy: 11.00%\n",
      "Round 5/200 starting...\n",
      "Round 5/200 completed.\n",
      " Avg Local Loss: 2.2588\n",
      " Global Loss: 2.2983, Accuracy: 11.21%\n",
      "Round 6/200 starting...\n",
      "Round 6/200 completed.\n",
      " Avg Local Loss: 2.2831\n",
      " Global Loss: 2.2942, Accuracy: 12.84%\n",
      "Round 7/200 starting...\n",
      "Round 7/200 completed.\n",
      " Avg Local Loss: 2.2605\n",
      " Global Loss: 2.2922, Accuracy: 13.10%\n",
      "Round 8/200 starting...\n",
      "Round 8/200 completed.\n",
      " Avg Local Loss: 2.2413\n",
      " Global Loss: 2.2905, Accuracy: 12.01%\n",
      "Round 9/200 starting...\n",
      "Round 9/200 completed.\n",
      " Avg Local Loss: 2.2284\n",
      " Global Loss: 2.2860, Accuracy: 13.01%\n",
      "Round 10/200 starting...\n",
      "Round 10/200 completed.\n",
      " Avg Local Loss: 2.2245\n",
      " Global Loss: 2.2839, Accuracy: 12.64%\n",
      "Round 11/200 starting...\n",
      "Round 11/200 completed.\n",
      " Avg Local Loss: 2.2069\n",
      " Global Loss: 2.2786, Accuracy: 16.27%\n",
      "Round 12/200 starting...\n",
      "Round 12/200 completed.\n",
      " Avg Local Loss: 2.1821\n",
      " Global Loss: 2.2736, Accuracy: 18.73%\n",
      "Round 13/200 starting...\n",
      "Round 13/200 completed.\n",
      " Avg Local Loss: 2.1553\n",
      " Global Loss: 2.2707, Accuracy: 14.94%\n",
      "Round 14/200 starting...\n",
      "Round 14/200 completed.\n",
      " Avg Local Loss: 2.1383\n",
      " Global Loss: 2.2654, Accuracy: 15.65%\n",
      "Round 15/200 starting...\n",
      "Round 15/200 completed.\n",
      " Avg Local Loss: 2.1550\n",
      " Global Loss: 2.2578, Accuracy: 14.38%\n",
      "Round 16/200 starting...\n",
      "Round 16/200 completed.\n",
      " Avg Local Loss: 2.1097\n",
      " Global Loss: 2.2527, Accuracy: 18.60%\n",
      "Round 17/200 starting...\n",
      "Round 17/200 completed.\n",
      " Avg Local Loss: 2.1334\n",
      " Global Loss: 2.2422, Accuracy: 17.86%\n",
      "Round 18/200 starting...\n",
      "Round 18/200 completed.\n",
      " Avg Local Loss: 2.0492\n",
      " Global Loss: 2.2408, Accuracy: 20.87%\n",
      "Round 19/200 starting...\n",
      "Round 19/200 completed.\n",
      " Avg Local Loss: 2.0063\n",
      " Global Loss: 2.2310, Accuracy: 17.24%\n",
      "Round 20/200 starting...\n",
      "Round 20/200 completed.\n",
      " Avg Local Loss: 1.9877\n",
      " Global Loss: 2.2344, Accuracy: 16.06%\n",
      "Round 21/200 starting...\n",
      "Round 21/200 completed.\n",
      " Avg Local Loss: 2.0768\n",
      " Global Loss: 2.2092, Accuracy: 22.80%\n",
      "Round 22/200 starting...\n",
      "Round 22/200 completed.\n",
      " Avg Local Loss: 1.9744\n",
      " Global Loss: 2.1988, Accuracy: 22.38%\n",
      "Round 23/200 starting...\n",
      "Round 23/200 completed.\n",
      " Avg Local Loss: 1.9858\n",
      " Global Loss: 2.1815, Accuracy: 24.66%\n",
      "Round 24/200 starting...\n",
      "Round 24/200 completed.\n",
      " Avg Local Loss: 1.8594\n",
      " Global Loss: 2.1747, Accuracy: 22.42%\n",
      "Round 25/200 starting...\n",
      "Round 25/200 completed.\n",
      " Avg Local Loss: 1.9731\n",
      " Global Loss: 2.1646, Accuracy: 21.82%\n",
      "Round 26/200 starting...\n",
      "Round 26/200 completed.\n",
      " Avg Local Loss: 1.8282\n",
      " Global Loss: 2.1516, Accuracy: 19.52%\n",
      "Round 27/200 starting...\n",
      "Round 27/200 completed.\n",
      " Avg Local Loss: 1.7963\n",
      " Global Loss: 2.1571, Accuracy: 19.16%\n",
      "Round 28/200 starting...\n",
      "Round 28/200 completed.\n",
      " Avg Local Loss: 1.8669\n",
      " Global Loss: 2.1393, Accuracy: 21.04%\n",
      "Round 29/200 starting...\n",
      "Round 29/200 completed.\n",
      " Avg Local Loss: 1.7422\n",
      " Global Loss: 2.1172, Accuracy: 22.10%\n",
      "Round 30/200 starting...\n",
      "Round 30/200 completed.\n",
      " Avg Local Loss: 1.7549\n",
      " Global Loss: 2.1111, Accuracy: 22.74%\n",
      "Round 31/200 starting...\n",
      "Round 31/200 completed.\n",
      " Avg Local Loss: 1.6765\n",
      " Global Loss: 2.1045, Accuracy: 24.37%\n",
      "Round 32/200 starting...\n",
      "Round 32/200 completed.\n",
      " Avg Local Loss: 1.7326\n",
      " Global Loss: 2.1197, Accuracy: 22.40%\n",
      "Round 33/200 starting...\n",
      "Round 33/200 completed.\n",
      " Avg Local Loss: 1.6180\n",
      " Global Loss: 2.0634, Accuracy: 27.47%\n",
      "Round 34/200 starting...\n",
      "Round 34/200 completed.\n",
      " Avg Local Loss: 1.6967\n",
      " Global Loss: 2.0550, Accuracy: 27.67%\n",
      "Round 35/200 starting...\n",
      "Round 35/200 completed.\n",
      " Avg Local Loss: 1.6250\n",
      " Global Loss: 2.0574, Accuracy: 27.57%\n",
      "Round 36/200 starting...\n",
      "Round 36/200 completed.\n",
      " Avg Local Loss: 1.5825\n",
      " Global Loss: 2.0218, Accuracy: 29.54%\n",
      "Round 37/200 starting...\n",
      "Round 37/200 completed.\n",
      " Avg Local Loss: 1.5667\n",
      " Global Loss: 2.0111, Accuracy: 28.88%\n",
      "Round 38/200 starting...\n",
      "Round 38/200 completed.\n",
      " Avg Local Loss: 1.5297\n",
      " Global Loss: 2.0053, Accuracy: 29.39%\n",
      "Round 39/200 starting...\n",
      "Round 39/200 completed.\n",
      " Avg Local Loss: 1.5273\n",
      " Global Loss: 1.9964, Accuracy: 29.29%\n",
      "Round 40/200 starting...\n",
      "Round 40/200 completed.\n",
      " Avg Local Loss: 1.5138\n",
      " Global Loss: 2.0074, Accuracy: 26.68%\n",
      "Round 41/200 starting...\n",
      "Round 41/200 completed.\n",
      " Avg Local Loss: 1.4670\n",
      " Global Loss: 2.0083, Accuracy: 28.11%\n",
      "Round 42/200 starting...\n",
      "Round 42/200 completed.\n",
      " Avg Local Loss: 1.5160\n",
      " Global Loss: 1.9802, Accuracy: 31.39%\n",
      "Round 43/200 starting...\n",
      "Round 43/200 completed.\n",
      " Avg Local Loss: 1.4869\n",
      " Global Loss: 1.9820, Accuracy: 28.38%\n",
      "Round 44/200 starting...\n",
      "Round 44/200 completed.\n",
      " Avg Local Loss: 1.4816\n",
      " Global Loss: 1.9572, Accuracy: 30.32%\n",
      "Round 45/200 starting...\n",
      "Round 45/200 completed.\n",
      " Avg Local Loss: 1.4692\n",
      " Global Loss: 2.0509, Accuracy: 25.83%\n",
      "Round 46/200 starting...\n",
      "Round 46/200 completed.\n",
      " Avg Local Loss: 1.4618\n",
      " Global Loss: 1.9386, Accuracy: 30.38%\n",
      "Round 47/200 starting...\n",
      "Round 47/200 completed.\n",
      " Avg Local Loss: 1.5371\n",
      " Global Loss: 1.9500, Accuracy: 30.25%\n",
      "Round 48/200 starting...\n",
      "Round 48/200 completed.\n",
      " Avg Local Loss: 1.4094\n",
      " Global Loss: 1.9657, Accuracy: 29.75%\n",
      "Round 49/200 starting...\n",
      "Round 49/200 completed.\n",
      " Avg Local Loss: 1.3786\n",
      " Global Loss: 1.9281, Accuracy: 31.81%\n",
      "Round 50/200 starting...\n",
      "Round 50/200 completed.\n",
      " Avg Local Loss: 1.3403\n",
      " Global Loss: 1.9324, Accuracy: 31.86%\n",
      "Round 51/200 starting...\n",
      "Round 51/200 completed.\n",
      " Avg Local Loss: 1.4045\n",
      " Global Loss: 1.9051, Accuracy: 32.35%\n",
      "Round 52/200 starting...\n",
      "Round 52/200 completed.\n",
      " Avg Local Loss: 1.3339\n",
      " Global Loss: 1.8846, Accuracy: 32.82%\n",
      "Round 53/200 starting...\n",
      "Round 53/200 completed.\n",
      " Avg Local Loss: 1.3033\n",
      " Global Loss: 1.8855, Accuracy: 32.62%\n",
      "Round 54/200 starting...\n",
      "Round 54/200 completed.\n",
      " Avg Local Loss: 1.3454\n",
      " Global Loss: 1.9037, Accuracy: 33.05%\n",
      "Round 55/200 starting...\n",
      "Round 55/200 completed.\n",
      " Avg Local Loss: 1.3443\n",
      " Global Loss: 1.8718, Accuracy: 34.08%\n",
      "Round 56/200 starting...\n",
      "Round 56/200 completed.\n",
      " Avg Local Loss: 1.3297\n",
      " Global Loss: 1.9236, Accuracy: 31.57%\n",
      "Round 57/200 starting...\n",
      "Round 57/200 completed.\n",
      " Avg Local Loss: 1.2753\n",
      " Global Loss: 1.8768, Accuracy: 33.28%\n",
      "Round 58/200 starting...\n",
      "Round 58/200 completed.\n",
      " Avg Local Loss: 1.3075\n",
      " Global Loss: 1.8937, Accuracy: 33.05%\n",
      "Round 59/200 starting...\n",
      "Round 59/200 completed.\n",
      " Avg Local Loss: 1.3446\n",
      " Global Loss: 1.8682, Accuracy: 32.25%\n",
      "Round 60/200 starting...\n",
      "Round 60/200 completed.\n",
      " Avg Local Loss: 1.3582\n",
      " Global Loss: 1.8908, Accuracy: 33.75%\n",
      "Round 61/200 starting...\n",
      "Round 61/200 completed.\n",
      " Avg Local Loss: 1.3747\n",
      " Global Loss: 1.9537, Accuracy: 31.32%\n",
      "Round 62/200 starting...\n",
      "Round 62/200 completed.\n",
      " Avg Local Loss: 1.1925\n",
      " Global Loss: 1.9347, Accuracy: 32.60%\n",
      "Round 63/200 starting...\n",
      "Round 63/200 completed.\n",
      " Avg Local Loss: 1.3592\n",
      " Global Loss: 1.8445, Accuracy: 34.60%\n",
      "Round 64/200 starting...\n",
      "Round 64/200 completed.\n",
      " Avg Local Loss: 1.2632\n",
      " Global Loss: 1.8612, Accuracy: 35.52%\n",
      "Round 65/200 starting...\n",
      "Round 65/200 completed.\n",
      " Avg Local Loss: 1.3113\n",
      " Global Loss: 1.9012, Accuracy: 32.87%\n",
      "Round 66/200 starting...\n",
      "Round 66/200 completed.\n",
      " Avg Local Loss: 1.2449\n",
      " Global Loss: 1.8186, Accuracy: 35.02%\n",
      "Round 67/200 starting...\n",
      "Round 67/200 completed.\n",
      " Avg Local Loss: 1.2380\n",
      " Global Loss: 1.8854, Accuracy: 33.08%\n",
      "Round 68/200 starting...\n",
      "Round 68/200 completed.\n",
      " Avg Local Loss: 1.3045\n",
      " Global Loss: 1.8432, Accuracy: 34.73%\n",
      "Round 69/200 starting...\n",
      "Round 69/200 completed.\n",
      " Avg Local Loss: 1.2422\n",
      " Global Loss: 1.8288, Accuracy: 35.09%\n",
      "Round 70/200 starting...\n",
      "Round 70/200 completed.\n",
      " Avg Local Loss: 1.2209\n",
      " Global Loss: 1.9202, Accuracy: 34.45%\n",
      "Round 71/200 starting...\n",
      "Round 71/200 completed.\n",
      " Avg Local Loss: 1.1983\n",
      " Global Loss: 1.7812, Accuracy: 36.96%\n",
      "Round 72/200 starting...\n",
      "Round 72/200 completed.\n",
      " Avg Local Loss: 1.2227\n",
      " Global Loss: 1.8407, Accuracy: 36.31%\n",
      "Round 73/200 starting...\n",
      "Round 73/200 completed.\n",
      " Avg Local Loss: 1.1696\n",
      " Global Loss: 1.7859, Accuracy: 36.85%\n",
      "Round 74/200 starting...\n",
      "Round 74/200 completed.\n",
      " Avg Local Loss: 1.3233\n",
      " Global Loss: 1.8240, Accuracy: 37.03%\n",
      "Round 75/200 starting...\n",
      "Round 75/200 completed.\n",
      " Avg Local Loss: 1.1516\n",
      " Global Loss: 1.8419, Accuracy: 36.08%\n",
      "Round 76/200 starting...\n",
      "Round 76/200 completed.\n",
      " Avg Local Loss: 1.1967\n",
      " Global Loss: 1.8781, Accuracy: 35.86%\n",
      "Round 77/200 starting...\n",
      "Round 77/200 completed.\n",
      " Avg Local Loss: 1.2103\n",
      " Global Loss: 1.7744, Accuracy: 37.78%\n",
      "Round 78/200 starting...\n",
      "Round 78/200 completed.\n",
      " Avg Local Loss: 1.1921\n",
      " Global Loss: 1.8491, Accuracy: 36.84%\n",
      "Round 79/200 starting...\n",
      "Round 79/200 completed.\n",
      " Avg Local Loss: 1.2466\n",
      " Global Loss: 1.8084, Accuracy: 35.85%\n",
      "Round 80/200 starting...\n",
      "Round 80/200 completed.\n",
      " Avg Local Loss: 1.2224\n",
      " Global Loss: 1.8714, Accuracy: 37.43%\n",
      "Round 81/200 starting...\n",
      "Round 81/200 completed.\n",
      " Avg Local Loss: 1.1930\n",
      " Global Loss: 1.7685, Accuracy: 38.33%\n",
      "Round 82/200 starting...\n",
      "Round 82/200 completed.\n",
      " Avg Local Loss: 1.2269\n",
      " Global Loss: 1.7840, Accuracy: 39.32%\n",
      "Round 83/200 starting...\n",
      "Round 83/200 completed.\n",
      " Avg Local Loss: 1.1826\n",
      " Global Loss: 1.7567, Accuracy: 39.04%\n",
      "Round 84/200 starting...\n",
      "Round 84/200 completed.\n",
      " Avg Local Loss: 1.1863\n",
      " Global Loss: 1.7789, Accuracy: 39.12%\n",
      "Round 85/200 starting...\n",
      "Round 85/200 completed.\n",
      " Avg Local Loss: 1.2449\n",
      " Global Loss: 1.8129, Accuracy: 38.32%\n",
      "Round 86/200 starting...\n",
      "Round 86/200 completed.\n",
      " Avg Local Loss: 1.1402\n",
      " Global Loss: 1.7831, Accuracy: 39.07%\n",
      "Round 87/200 starting...\n",
      "Round 87/200 completed.\n",
      " Avg Local Loss: 1.1396\n",
      " Global Loss: 1.8676, Accuracy: 38.53%\n",
      "Round 88/200 starting...\n",
      "Round 88/200 completed.\n",
      " Avg Local Loss: 1.2060\n",
      " Global Loss: 1.8176, Accuracy: 39.32%\n",
      "Round 89/200 starting...\n",
      "Round 89/200 completed.\n",
      " Avg Local Loss: 1.1917\n",
      " Global Loss: 1.8196, Accuracy: 37.64%\n",
      "Round 90/200 starting...\n",
      "Round 90/200 completed.\n",
      " Avg Local Loss: 1.1286\n",
      " Global Loss: 1.7946, Accuracy: 38.88%\n",
      "Round 91/200 starting...\n",
      "Round 91/200 completed.\n",
      " Avg Local Loss: 1.1765\n",
      " Global Loss: 1.7597, Accuracy: 40.32%\n",
      "Round 92/200 starting...\n",
      "Round 92/200 completed.\n",
      " Avg Local Loss: 1.1549\n",
      " Global Loss: 1.7417, Accuracy: 41.29%\n",
      "Round 93/200 starting...\n",
      "Round 93/200 completed.\n",
      " Avg Local Loss: 1.0684\n",
      " Global Loss: 1.6918, Accuracy: 42.13%\n",
      "Round 94/200 starting...\n",
      "Round 94/200 completed.\n",
      " Avg Local Loss: 1.1210\n",
      " Global Loss: 1.7731, Accuracy: 40.09%\n",
      "Round 95/200 starting...\n",
      "Round 95/200 completed.\n",
      " Avg Local Loss: 1.1528\n",
      " Global Loss: 1.7748, Accuracy: 40.05%\n",
      "Round 96/200 starting...\n",
      "Round 96/200 completed.\n",
      " Avg Local Loss: 1.2157\n",
      " Global Loss: 1.7437, Accuracy: 40.55%\n",
      "Round 97/200 starting...\n",
      "Round 97/200 completed.\n",
      " Avg Local Loss: 1.1679\n",
      " Global Loss: 1.8609, Accuracy: 39.67%\n",
      "Round 98/200 starting...\n",
      "Round 98/200 completed.\n",
      " Avg Local Loss: 1.0965\n",
      " Global Loss: 1.6746, Accuracy: 42.93%\n",
      "Round 99/200 starting...\n",
      "Round 99/200 completed.\n",
      " Avg Local Loss: 1.1220\n",
      " Global Loss: 1.7682, Accuracy: 41.30%\n",
      "Round 100/200 starting...\n",
      "Round 100/200 completed.\n",
      " Avg Local Loss: 1.2220\n",
      " Global Loss: 1.7324, Accuracy: 42.50%\n",
      "Round 101/200 starting...\n",
      "Round 101/200 completed.\n",
      " Avg Local Loss: 1.1814\n",
      " Global Loss: 1.7233, Accuracy: 42.92%\n",
      "Round 102/200 starting...\n",
      "Round 102/200 completed.\n",
      " Avg Local Loss: 1.1178\n",
      " Global Loss: 1.7364, Accuracy: 42.75%\n",
      "Round 103/200 starting...\n",
      "Round 103/200 completed.\n",
      " Avg Local Loss: 1.1959\n",
      " Global Loss: 1.8011, Accuracy: 41.66%\n",
      "Round 104/200 starting...\n",
      "Round 104/200 completed.\n",
      " Avg Local Loss: 1.2091\n",
      " Global Loss: 1.7686, Accuracy: 42.55%\n",
      "Round 105/200 starting...\n",
      "Round 105/200 completed.\n",
      " Avg Local Loss: 1.1869\n",
      " Global Loss: 1.7393, Accuracy: 43.17%\n",
      "Round 106/200 starting...\n",
      "Round 106/200 completed.\n",
      " Avg Local Loss: 1.2233\n",
      " Global Loss: 1.9913, Accuracy: 38.16%\n",
      "Round 107/200 starting...\n",
      "Round 107/200 completed.\n",
      " Avg Local Loss: 1.2369\n",
      " Global Loss: 1.9037, Accuracy: 40.89%\n",
      "Round 108/200 starting...\n",
      "Round 108/200 completed.\n",
      " Avg Local Loss: 1.1297\n",
      " Global Loss: 1.7059, Accuracy: 44.30%\n",
      "Round 109/200 starting...\n",
      "Round 109/200 completed.\n",
      " Avg Local Loss: 1.1858\n",
      " Global Loss: 1.7733, Accuracy: 43.51%\n",
      "Round 110/200 starting...\n",
      "Round 110/200 completed.\n",
      " Avg Local Loss: 1.3252\n",
      " Global Loss: 1.8771, Accuracy: 42.07%\n",
      "Round 111/200 starting...\n",
      "Round 111/200 completed.\n",
      " Avg Local Loss: 1.2524\n",
      " Global Loss: 2.0390, Accuracy: 40.55%\n",
      "Round 112/200 starting...\n",
      "Round 112/200 completed.\n",
      " Avg Local Loss: 1.2751\n",
      " Global Loss: 1.9419, Accuracy: 41.91%\n",
      "Round 113/200 starting...\n",
      "Round 113/200 completed.\n",
      " Avg Local Loss: 1.1586\n",
      " Global Loss: 1.8509, Accuracy: 44.18%\n",
      "Round 114/200 starting...\n",
      "Round 114/200 completed.\n",
      " Avg Local Loss: 1.3018\n",
      " Global Loss: 1.9600, Accuracy: 42.23%\n",
      "Round 115/200 starting...\n",
      "Round 115/200 completed.\n",
      " Avg Local Loss: 1.3171\n",
      " Global Loss: 1.8149, Accuracy: 44.93%\n",
      "Round 116/200 starting...\n",
      "Round 116/200 completed.\n",
      " Avg Local Loss: 1.4627\n",
      " Global Loss: 1.9828, Accuracy: 43.04%\n",
      "Round 117/200 starting...\n",
      "Round 117/200 completed.\n",
      " Avg Local Loss: 1.4619\n",
      " Global Loss: 2.0517, Accuracy: 42.90%\n",
      "Round 118/200 starting...\n",
      "Round 118/200 completed.\n",
      " Avg Local Loss: 1.4872\n",
      " Global Loss: 2.1491, Accuracy: 41.30%\n",
      "Round 119/200 starting...\n",
      "Round 119/200 completed.\n",
      " Avg Local Loss: 1.3328\n",
      " Global Loss: 1.9930, Accuracy: 43.36%\n",
      "Round 120/200 starting...\n",
      "Round 120/200 completed.\n",
      " Avg Local Loss: 1.3356\n",
      " Global Loss: 1.9004, Accuracy: 44.63%\n",
      "Round 121/200 starting...\n",
      "Round 121/200 completed.\n",
      " Avg Local Loss: 1.3944\n",
      " Global Loss: 2.0377, Accuracy: 44.10%\n",
      "Round 122/200 starting...\n",
      "Round 122/200 completed.\n",
      " Avg Local Loss: 1.6139\n",
      " Global Loss: 2.7980, Accuracy: 37.90%\n",
      "Round 123/200 starting...\n",
      "Round 123/200 completed.\n",
      " Avg Local Loss: 1.5273\n",
      " Global Loss: 2.2960, Accuracy: 40.38%\n",
      "Round 124/200 starting...\n",
      "Round 124/200 completed.\n",
      " Avg Local Loss: 1.5678\n",
      " Global Loss: 2.1119, Accuracy: 43.46%\n",
      "Round 125/200 starting...\n",
      "Round 125/200 completed.\n",
      " Avg Local Loss: 1.8114\n",
      " Global Loss: 2.0134, Accuracy: 45.66%\n",
      "Round 126/200 starting...\n",
      "Round 126/200 completed.\n",
      " Avg Local Loss: 1.6863\n",
      " Global Loss: 2.3848, Accuracy: 43.59%\n",
      "Round 127/200 starting...\n",
      "Round 127/200 completed.\n",
      " Avg Local Loss: 1.9600\n",
      " Global Loss: 2.1358, Accuracy: 44.88%\n",
      "Round 128/200 starting...\n",
      "Round 128/200 completed.\n",
      " Avg Local Loss: 1.7338\n",
      " Global Loss: 2.1069, Accuracy: 45.57%\n",
      "Round 129/200 starting...\n",
      "Round 129/200 completed.\n",
      " Avg Local Loss: 1.7262\n",
      " Global Loss: 2.2568, Accuracy: 44.31%\n",
      "Round 130/200 starting...\n",
      "Round 130/200 completed.\n",
      " Avg Local Loss: 1.9642\n",
      " Global Loss: 2.7055, Accuracy: 41.48%\n",
      "Round 131/200 starting...\n",
      "Round 131/200 completed.\n",
      " Avg Local Loss: 1.8864\n",
      " Global Loss: 2.1964, Accuracy: 45.25%\n",
      "Round 132/200 starting...\n",
      "Round 132/200 completed.\n",
      " Avg Local Loss: 1.6047\n",
      " Global Loss: 2.2448, Accuracy: 45.20%\n",
      "Round 133/200 starting...\n",
      "Round 133/200 completed.\n",
      " Avg Local Loss: 1.8917\n",
      " Global Loss: 3.0895, Accuracy: 38.99%\n",
      "Round 134/200 starting...\n",
      "Round 134/200 completed.\n",
      " Avg Local Loss: 1.9368\n",
      " Global Loss: 2.9672, Accuracy: 40.00%\n",
      "Round 135/200 starting...\n",
      "Round 135/200 completed.\n",
      " Avg Local Loss: 1.8148\n",
      " Global Loss: 2.5004, Accuracy: 44.94%\n",
      "Round 136/200 starting...\n",
      "Round 136/200 completed.\n",
      " Avg Local Loss: 2.2893\n",
      " Global Loss: 2.7320, Accuracy: 42.22%\n",
      "Round 137/200 starting...\n",
      "Round 137/200 completed.\n",
      " Avg Local Loss: 2.0131\n",
      " Global Loss: 3.4198, Accuracy: 40.30%\n",
      "Round 138/200 starting...\n",
      "Round 138/200 completed.\n",
      " Avg Local Loss: 1.9797\n",
      " Global Loss: 2.7361, Accuracy: 44.08%\n",
      "Round 139/200 starting...\n",
      "Round 139/200 completed.\n",
      " Avg Local Loss: 1.9770\n",
      " Global Loss: 3.2174, Accuracy: 42.71%\n",
      "Round 140/200 starting...\n",
      "Round 140/200 completed.\n",
      " Avg Local Loss: 1.7755\n",
      " Global Loss: 3.0223, Accuracy: 43.80%\n",
      "Round 141/200 starting...\n",
      "Round 141/200 completed.\n",
      " Avg Local Loss: 2.2908\n",
      " Global Loss: 3.2570, Accuracy: 41.12%\n",
      "Round 142/200 starting...\n",
      "Round 142/200 completed.\n",
      " Avg Local Loss: 1.8586\n",
      " Global Loss: 2.7730, Accuracy: 45.95%\n",
      "Round 143/200 starting...\n",
      "Round 143/200 completed.\n",
      " Avg Local Loss: 1.9949\n",
      " Global Loss: 2.6308, Accuracy: 46.79%\n",
      "Round 144/200 starting...\n",
      "Round 144/200 completed.\n",
      " Avg Local Loss: 2.0759\n",
      " Global Loss: 2.8942, Accuracy: 45.63%\n",
      "Round 145/200 starting...\n",
      "Round 145/200 completed.\n",
      " Avg Local Loss: 1.9134\n",
      " Global Loss: 2.8270, Accuracy: 46.63%\n",
      "Round 146/200 starting...\n",
      "Round 146/200 completed.\n",
      " Avg Local Loss: 2.1921\n",
      " Global Loss: 3.0341, Accuracy: 45.37%\n",
      "Round 147/200 starting...\n",
      "Round 147/200 completed.\n",
      " Avg Local Loss: 2.1385\n",
      " Global Loss: 3.0966, Accuracy: 46.33%\n",
      "Round 148/200 starting...\n",
      "Round 148/200 completed.\n",
      " Avg Local Loss: 2.2210\n",
      " Global Loss: 2.9982, Accuracy: 46.66%\n",
      "Round 149/200 starting...\n",
      "Round 149/200 completed.\n",
      " Avg Local Loss: 2.0482\n",
      " Global Loss: 3.2867, Accuracy: 45.91%\n",
      "Round 150/200 starting...\n",
      "Round 150/200 completed.\n",
      " Avg Local Loss: 2.5811\n",
      " Global Loss: 3.2178, Accuracy: 45.86%\n",
      "Round 151/200 starting...\n",
      "Round 151/200 completed.\n",
      " Avg Local Loss: 2.6775\n",
      " Global Loss: 3.2097, Accuracy: 46.04%\n",
      "Round 152/200 starting...\n",
      "Round 152/200 completed.\n",
      " Avg Local Loss: 2.2664\n",
      " Global Loss: 3.1386, Accuracy: 47.62%\n",
      "Round 153/200 starting...\n",
      "Round 153/200 completed.\n",
      " Avg Local Loss: 2.2690\n",
      " Global Loss: 3.1708, Accuracy: 47.56%\n",
      "Round 154/200 starting...\n",
      "Round 154/200 completed.\n",
      " Avg Local Loss: 2.7972\n",
      " Global Loss: 4.1716, Accuracy: 43.26%\n",
      "Round 155/200 starting...\n",
      "Round 155/200 completed.\n",
      " Avg Local Loss: 2.4884\n",
      " Global Loss: 3.8881, Accuracy: 45.24%\n",
      "Round 156/200 starting...\n",
      "Round 156/200 completed.\n",
      " Avg Local Loss: 2.5986\n",
      " Global Loss: 4.5108, Accuracy: 41.89%\n",
      "Round 157/200 starting...\n",
      "Round 157/200 completed.\n",
      " Avg Local Loss: 2.9437\n",
      " Global Loss: 3.6060, Accuracy: 46.82%\n",
      "Round 158/200 starting...\n",
      "Round 158/200 completed.\n",
      " Avg Local Loss: 2.4036\n",
      " Global Loss: 3.8667, Accuracy: 46.09%\n",
      "Round 159/200 starting...\n",
      "Round 159/200 completed.\n",
      " Avg Local Loss: 2.5812\n",
      " Global Loss: 4.6660, Accuracy: 41.60%\n",
      "Round 160/200 starting...\n",
      "Round 160/200 completed.\n",
      " Avg Local Loss: 2.8617\n",
      " Global Loss: 4.0718, Accuracy: 45.30%\n",
      "Round 161/200 starting...\n",
      "Round 161/200 completed.\n",
      " Avg Local Loss: 2.6994\n",
      " Global Loss: 3.8804, Accuracy: 46.99%\n",
      "Round 162/200 starting...\n",
      "Round 162/200 completed.\n",
      " Avg Local Loss: 2.5431\n",
      " Global Loss: 4.0159, Accuracy: 47.54%\n",
      "Round 163/200 starting...\n",
      "Round 163/200 completed.\n",
      " Avg Local Loss: 2.9581\n",
      " Global Loss: 4.3948, Accuracy: 45.52%\n",
      "Round 164/200 starting...\n",
      "Round 164/200 completed.\n",
      " Avg Local Loss: 2.9269\n",
      " Global Loss: 4.1775, Accuracy: 47.01%\n",
      "Round 165/200 starting...\n",
      "Round 165/200 completed.\n",
      " Avg Local Loss: 2.9808\n",
      " Global Loss: 5.5922, Accuracy: 41.09%\n",
      "Round 166/200 starting...\n",
      "Round 166/200 completed.\n",
      " Avg Local Loss: 3.0451\n",
      " Global Loss: 4.4634, Accuracy: 46.48%\n",
      "Round 167/200 starting...\n",
      "Round 167/200 completed.\n",
      " Avg Local Loss: 2.6293\n",
      " Global Loss: 4.8749, Accuracy: 46.24%\n",
      "Round 168/200 starting...\n",
      "Round 168/200 completed.\n",
      " Avg Local Loss: 3.0802\n",
      " Global Loss: 4.5876, Accuracy: 45.51%\n",
      "Round 169/200 starting...\n",
      "Round 169/200 completed.\n",
      " Avg Local Loss: 2.9808\n",
      " Global Loss: 4.7819, Accuracy: 46.02%\n",
      "Round 170/200 starting...\n",
      "Round 170/200 completed.\n",
      " Avg Local Loss: 2.8909\n",
      " Global Loss: 4.8168, Accuracy: 46.95%\n",
      "Round 171/200 starting...\n",
      "Round 171/200 completed.\n",
      " Avg Local Loss: 3.0284\n",
      " Global Loss: 4.7827, Accuracy: 47.64%\n",
      "Round 172/200 starting...\n",
      "Round 172/200 completed.\n",
      " Avg Local Loss: 3.2039\n",
      " Global Loss: 5.0449, Accuracy: 46.82%\n",
      "Round 173/200 starting...\n",
      "Round 173/200 completed.\n",
      " Avg Local Loss: 3.3035\n",
      " Global Loss: 5.4516, Accuracy: 45.41%\n",
      "Round 174/200 starting...\n",
      "Round 174/200 completed.\n",
      " Avg Local Loss: 3.4486\n",
      " Global Loss: 5.1475, Accuracy: 47.04%\n",
      "Round 175/200 starting...\n",
      "Round 175/200 completed.\n",
      " Avg Local Loss: 3.1653\n",
      " Global Loss: 5.3100, Accuracy: 46.75%\n",
      "Round 176/200 starting...\n",
      "Round 176/200 completed.\n",
      " Avg Local Loss: 3.0282\n",
      " Global Loss: 5.4928, Accuracy: 47.46%\n",
      "Round 177/200 starting...\n",
      "Round 177/200 completed.\n",
      " Avg Local Loss: 3.1889\n",
      " Global Loss: 5.7172, Accuracy: 46.95%\n",
      "Round 178/200 starting...\n",
      "Round 178/200 completed.\n",
      " Avg Local Loss: 3.3885\n",
      " Global Loss: 5.9741, Accuracy: 45.92%\n",
      "Round 179/200 starting...\n",
      "Round 179/200 completed.\n",
      " Avg Local Loss: 3.5264\n",
      " Global Loss: 5.9086, Accuracy: 46.91%\n",
      "Round 180/200 starting...\n",
      "Round 180/200 completed.\n",
      " Avg Local Loss: 3.9040\n",
      " Global Loss: 6.0431, Accuracy: 47.31%\n",
      "Round 181/200 starting...\n",
      "Round 181/200 completed.\n",
      " Avg Local Loss: 3.8450\n",
      " Global Loss: 6.1501, Accuracy: 45.78%\n",
      "Round 182/200 starting...\n",
      "Round 182/200 completed.\n",
      " Avg Local Loss: 3.4923\n",
      " Global Loss: 6.2202, Accuracy: 46.63%\n",
      "Round 183/200 starting...\n",
      "Round 183/200 completed.\n",
      " Avg Local Loss: 3.5847\n",
      " Global Loss: 6.1991, Accuracy: 47.77%\n",
      "Round 184/200 starting...\n",
      "Round 184/200 completed.\n",
      " Avg Local Loss: 3.9064\n",
      " Global Loss: 6.4820, Accuracy: 46.74%\n",
      "Round 185/200 starting...\n",
      "Round 185/200 completed.\n",
      " Avg Local Loss: 3.9259\n",
      " Global Loss: 7.4607, Accuracy: 44.41%\n",
      "Round 186/200 starting...\n",
      "Round 186/200 completed.\n",
      " Avg Local Loss: 4.0400\n",
      " Global Loss: 7.0742, Accuracy: 46.30%\n",
      "Round 187/200 starting...\n",
      "Round 187/200 completed.\n",
      " Avg Local Loss: 4.1454\n",
      " Global Loss: 7.0128, Accuracy: 46.97%\n",
      "Round 188/200 starting...\n",
      "Round 188/200 completed.\n",
      " Avg Local Loss: 4.0253\n",
      " Global Loss: 7.3931, Accuracy: 46.00%\n",
      "Round 189/200 starting...\n",
      "Round 189/200 completed.\n",
      " Avg Local Loss: 3.9821\n",
      " Global Loss: 7.9316, Accuracy: 44.68%\n",
      "Round 190/200 starting...\n",
      "Round 190/200 completed.\n",
      " Avg Local Loss: 4.2282\n",
      " Global Loss: 7.6050, Accuracy: 46.44%\n",
      "Round 191/200 starting...\n",
      "Round 191/200 completed.\n",
      " Avg Local Loss: 3.9235\n",
      " Global Loss: 7.5752, Accuracy: 46.35%\n",
      "Round 192/200 starting...\n",
      "Round 192/200 completed.\n",
      " Avg Local Loss: 4.3815\n",
      " Global Loss: 7.8665, Accuracy: 46.99%\n",
      "Round 193/200 starting...\n",
      "Round 193/200 completed.\n",
      " Avg Local Loss: 3.9870\n",
      " Global Loss: 8.8207, Accuracy: 46.05%\n",
      "Round 194/200 starting...\n",
      "Round 194/200 completed.\n",
      " Avg Local Loss: 4.6103\n",
      " Global Loss: 8.3035, Accuracy: 46.67%\n",
      "Round 195/200 starting...\n",
      "Round 195/200 completed.\n",
      " Avg Local Loss: 4.2599\n",
      " Global Loss: 8.6000, Accuracy: 47.17%\n",
      "Round 196/200 starting...\n",
      "Round 196/200 completed.\n",
      " Avg Local Loss: 4.5791\n",
      " Global Loss: 8.9852, Accuracy: 46.01%\n",
      "Round 197/200 starting...\n",
      "Round 197/200 completed.\n",
      " Avg Local Loss: 4.6738\n",
      " Global Loss: 8.7073, Accuracy: 46.80%\n",
      "Round 198/200 starting...\n",
      "Round 198/200 completed.\n",
      " Avg Local Loss: 4.7264\n",
      " Global Loss: 9.2418, Accuracy: 46.02%\n",
      "Round 199/200 starting...\n",
      "Round 199/200 completed.\n",
      " Avg Local Loss: 4.6217\n",
      " Global Loss: 9.5973, Accuracy: 46.47%\n",
      "Round 200/200 starting...\n",
      "Round 200/200 completed.\n",
      " Avg Local Loss: 5.2304\n",
      " Global Loss: 9.8358, Accuracy: 46.00%\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "learning_rate = 0.0002\n",
    "momentum = 0.01\n",
    "mu = 0\n",
    "method = 'FedAvgM'\n",
    "\n",
    "federated_learning_with_scenario(server_class=Server, user_class=User, global_model_class=SimpleCNN, dataset=cifar10_train, test_loader=test_loader,\n",
    "        num_users=num_users,\n",
    "        rounds=rounds,\n",
    "        epochs=epochs,\n",
    "        fraction=fraction,\n",
    "        iid=iid,\n",
    "        lr=learning_rate,\n",
    "        alpha=alpha,\n",
    "        method=method,\n",
    "        momentum=momentum,\n",
    "        mu=mu,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: Non-IID with 20 users (alpha=0.5).\n",
      "Round 1/200 starting...\n",
      "Round 1/200 completed.\n",
      " Avg Local Loss: 1.4621\n",
      " Global Loss: 2.0178, Accuracy: 28.70%\n",
      "Round 2/200 starting...\n",
      "Round 2/200 completed.\n",
      " Avg Local Loss: 1.1767\n",
      " Global Loss: 1.7090, Accuracy: 37.24%\n",
      "Round 3/200 starting...\n",
      "Round 3/200 completed.\n",
      " Avg Local Loss: 1.0290\n",
      " Global Loss: 1.5668, Accuracy: 42.21%\n",
      "Round 4/200 starting...\n",
      "Round 4/200 completed.\n",
      " Avg Local Loss: 0.9361\n",
      " Global Loss: 1.4691, Accuracy: 49.20%\n",
      "Round 5/200 starting...\n",
      "Round 5/200 completed.\n",
      " Avg Local Loss: 0.8172\n",
      " Global Loss: 1.3487, Accuracy: 51.28%\n",
      "Round 6/200 starting...\n",
      "Round 6/200 completed.\n",
      " Avg Local Loss: 0.7572\n",
      " Global Loss: 1.3543, Accuracy: 52.16%\n",
      "Round 7/200 starting...\n",
      "Round 7/200 completed.\n",
      " Avg Local Loss: 0.6613\n",
      " Global Loss: 1.3462, Accuracy: 54.17%\n",
      "Round 8/200 starting...\n",
      "Round 8/200 completed.\n",
      " Avg Local Loss: 0.6710\n",
      " Global Loss: 1.2918, Accuracy: 55.27%\n",
      "Round 9/200 starting...\n",
      "Round 9/200 completed.\n",
      " Avg Local Loss: 0.6146\n",
      " Global Loss: 1.2314, Accuracy: 58.30%\n",
      "Round 10/200 starting...\n",
      "Round 10/200 completed.\n",
      " Avg Local Loss: 0.5505\n",
      " Global Loss: 1.2458, Accuracy: 58.31%\n",
      "Round 11/200 starting...\n",
      "Round 11/200 completed.\n",
      " Avg Local Loss: 0.4119\n",
      " Global Loss: 1.2859, Accuracy: 59.67%\n",
      "Round 12/200 starting...\n",
      "Round 12/200 completed.\n",
      " Avg Local Loss: 0.3452\n",
      " Global Loss: 1.3647, Accuracy: 58.76%\n",
      "Round 13/200 starting...\n",
      "Round 13/200 completed.\n",
      " Avg Local Loss: 0.3215\n",
      " Global Loss: 1.4045, Accuracy: 58.67%\n",
      "Round 14/200 starting...\n",
      "Round 14/200 completed.\n",
      " Avg Local Loss: 0.3221\n",
      " Global Loss: 1.5003, Accuracy: 58.55%\n",
      "Round 15/200 starting...\n",
      "Round 15/200 completed.\n",
      " Avg Local Loss: 0.2917\n",
      " Global Loss: 1.4023, Accuracy: 60.21%\n",
      "Round 16/200 starting...\n",
      "Round 16/200 completed.\n",
      " Avg Local Loss: 0.2411\n",
      " Global Loss: 1.4437, Accuracy: 59.91%\n",
      "Round 17/200 starting...\n",
      "Round 17/200 completed.\n",
      " Avg Local Loss: 0.2707\n",
      " Global Loss: 1.3932, Accuracy: 61.30%\n",
      "Round 18/200 starting...\n",
      "Round 18/200 completed.\n",
      " Avg Local Loss: 0.2072\n",
      " Global Loss: 1.4508, Accuracy: 60.89%\n",
      "Round 19/200 starting...\n",
      "Round 19/200 completed.\n",
      " Avg Local Loss: 0.2278\n",
      " Global Loss: 1.3942, Accuracy: 61.72%\n",
      "Round 20/200 starting...\n",
      "Round 20/200 completed.\n",
      " Avg Local Loss: 0.2451\n",
      " Global Loss: 1.4148, Accuracy: 61.74%\n",
      "Round 21/200 starting...\n",
      "Round 21/200 completed.\n",
      " Avg Local Loss: 0.2268\n",
      " Global Loss: 1.4327, Accuracy: 62.02%\n",
      "Round 22/200 starting...\n",
      "Round 22/200 completed.\n",
      " Avg Local Loss: 0.1676\n",
      " Global Loss: 1.4644, Accuracy: 62.14%\n",
      "Round 23/200 starting...\n",
      "Round 23/200 completed.\n",
      " Avg Local Loss: 0.1771\n",
      " Global Loss: 1.4551, Accuracy: 62.46%\n",
      "Round 24/200 starting...\n",
      "Round 24/200 completed.\n",
      " Avg Local Loss: 0.1609\n",
      " Global Loss: 1.5167, Accuracy: 61.45%\n",
      "Round 25/200 starting...\n",
      "Round 25/200 completed.\n",
      " Avg Local Loss: 0.1518\n",
      " Global Loss: 1.6016, Accuracy: 60.60%\n",
      "Round 26/200 starting...\n",
      "Round 26/200 completed.\n",
      " Avg Local Loss: 0.1777\n",
      " Global Loss: 1.4719, Accuracy: 62.76%\n",
      "Round 27/200 starting...\n",
      "Round 27/200 completed.\n",
      " Avg Local Loss: 0.1562\n",
      " Global Loss: 1.4900, Accuracy: 62.61%\n",
      "Round 28/200 starting...\n",
      "Round 28/200 completed.\n",
      " Avg Local Loss: 0.1234\n",
      " Global Loss: 1.5651, Accuracy: 61.88%\n",
      "Round 29/200 starting...\n",
      "Round 29/200 completed.\n",
      " Avg Local Loss: 0.1422\n",
      " Global Loss: 1.5456, Accuracy: 61.84%\n",
      "Round 30/200 starting...\n",
      "Round 30/200 completed.\n",
      " Avg Local Loss: 0.1386\n",
      " Global Loss: 1.5446, Accuracy: 61.50%\n",
      "Round 31/200 starting...\n",
      "Round 31/200 completed.\n",
      " Avg Local Loss: 0.1402\n",
      " Global Loss: 1.5853, Accuracy: 62.08%\n",
      "Round 32/200 starting...\n",
      "Round 32/200 completed.\n",
      " Avg Local Loss: 0.1278\n",
      " Global Loss: 1.6043, Accuracy: 61.62%\n",
      "Round 33/200 starting...\n",
      "Round 33/200 completed.\n",
      " Avg Local Loss: 0.1174\n",
      " Global Loss: 1.6043, Accuracy: 62.39%\n",
      "Round 34/200 starting...\n",
      "Round 34/200 completed.\n",
      " Avg Local Loss: 0.1136\n",
      " Global Loss: 1.5286, Accuracy: 62.70%\n",
      "Round 35/200 starting...\n",
      "Round 35/200 completed.\n",
      " Avg Local Loss: 0.1292\n",
      " Global Loss: 1.5250, Accuracy: 62.63%\n",
      "Round 36/200 starting...\n",
      "Round 36/200 completed.\n",
      " Avg Local Loss: 0.1007\n",
      " Global Loss: 1.6226, Accuracy: 62.22%\n",
      "Round 37/200 starting...\n",
      "Round 37/200 completed.\n",
      " Avg Local Loss: 0.1121\n",
      " Global Loss: 1.5791, Accuracy: 62.31%\n",
      "Round 38/200 starting...\n",
      "Round 38/200 completed.\n",
      " Avg Local Loss: 0.0965\n",
      " Global Loss: 1.6680, Accuracy: 61.78%\n",
      "Round 39/200 starting...\n",
      "Round 39/200 completed.\n",
      " Avg Local Loss: 0.1011\n",
      " Global Loss: 1.6192, Accuracy: 62.60%\n",
      "Round 40/200 starting...\n",
      "Round 40/200 completed.\n",
      " Avg Local Loss: 0.1033\n",
      " Global Loss: 1.5357, Accuracy: 63.93%\n",
      "Round 41/200 starting...\n",
      "Round 41/200 completed.\n",
      " Avg Local Loss: 0.1073\n",
      " Global Loss: 1.6108, Accuracy: 62.45%\n",
      "Round 42/200 starting...\n",
      "Round 42/200 completed.\n",
      " Avg Local Loss: 0.0934\n",
      " Global Loss: 1.6398, Accuracy: 63.01%\n",
      "Round 43/200 starting...\n",
      "Round 43/200 completed.\n",
      " Avg Local Loss: 0.1019\n",
      " Global Loss: 1.6815, Accuracy: 62.47%\n",
      "Round 44/200 starting...\n",
      "Round 44/200 completed.\n",
      " Avg Local Loss: 0.0860\n",
      " Global Loss: 1.6301, Accuracy: 62.84%\n",
      "Round 45/200 starting...\n",
      "Round 45/200 completed.\n",
      " Avg Local Loss: 0.0842\n",
      " Global Loss: 1.7495, Accuracy: 61.90%\n",
      "Round 46/200 starting...\n",
      "Round 46/200 completed.\n",
      " Avg Local Loss: 0.0827\n",
      " Global Loss: 1.6112, Accuracy: 63.01%\n",
      "Round 47/200 starting...\n",
      "Round 47/200 completed.\n",
      " Avg Local Loss: 0.0859\n",
      " Global Loss: 1.6483, Accuracy: 62.94%\n",
      "Round 48/200 starting...\n",
      "Round 48/200 completed.\n",
      " Avg Local Loss: 0.0716\n",
      " Global Loss: 1.6444, Accuracy: 63.12%\n",
      "Round 49/200 starting...\n",
      "Round 49/200 completed.\n",
      " Avg Local Loss: 0.0712\n",
      " Global Loss: 1.6603, Accuracy: 63.15%\n",
      "Round 50/200 starting...\n",
      "Round 50/200 completed.\n",
      " Avg Local Loss: 0.0689\n",
      " Global Loss: 1.7138, Accuracy: 62.52%\n",
      "Round 51/200 starting...\n",
      "Round 51/200 completed.\n",
      " Avg Local Loss: 0.0589\n",
      " Global Loss: 1.8717, Accuracy: 61.48%\n",
      "Round 52/200 starting...\n",
      "Round 52/200 completed.\n",
      " Avg Local Loss: 0.0721\n",
      " Global Loss: 1.8279, Accuracy: 62.06%\n",
      "Round 53/200 starting...\n",
      "Round 53/200 completed.\n",
      " Avg Local Loss: 0.0853\n",
      " Global Loss: 1.7138, Accuracy: 62.78%\n",
      "Round 54/200 starting...\n",
      "Round 54/200 completed.\n",
      " Avg Local Loss: 0.0554\n",
      " Global Loss: 1.7544, Accuracy: 62.48%\n",
      "Round 55/200 starting...\n",
      "Round 55/200 completed.\n",
      " Avg Local Loss: 0.0535\n",
      " Global Loss: 1.7485, Accuracy: 63.20%\n",
      "Round 56/200 starting...\n",
      "Round 56/200 completed.\n",
      " Avg Local Loss: 0.0672\n",
      " Global Loss: 1.8359, Accuracy: 61.63%\n",
      "Round 57/200 starting...\n",
      "Round 57/200 completed.\n",
      " Avg Local Loss: 0.0539\n",
      " Global Loss: 1.7444, Accuracy: 62.80%\n",
      "Round 58/200 starting...\n",
      "Round 58/200 completed.\n",
      " Avg Local Loss: 0.0527\n",
      " Global Loss: 1.8542, Accuracy: 62.09%\n",
      "Round 59/200 starting...\n",
      "Round 59/200 completed.\n",
      " Avg Local Loss: 0.0547\n",
      " Global Loss: 1.8600, Accuracy: 61.79%\n",
      "Round 60/200 starting...\n",
      "Round 60/200 completed.\n",
      " Avg Local Loss: 0.0571\n",
      " Global Loss: 1.7440, Accuracy: 62.76%\n",
      "Round 61/200 starting...\n",
      "Round 61/200 completed.\n",
      " Avg Local Loss: 0.0461\n",
      " Global Loss: 1.8029, Accuracy: 63.38%\n",
      "Round 62/200 starting...\n",
      "Round 62/200 completed.\n",
      " Avg Local Loss: 0.0403\n",
      " Global Loss: 1.9557, Accuracy: 62.02%\n",
      "Round 63/200 starting...\n",
      "Round 63/200 completed.\n",
      " Avg Local Loss: 0.0528\n",
      " Global Loss: 1.7850, Accuracy: 62.97%\n",
      "Round 64/200 starting...\n",
      "Round 64/200 completed.\n",
      " Avg Local Loss: 0.0457\n",
      " Global Loss: 1.9133, Accuracy: 61.86%\n",
      "Round 65/200 starting...\n",
      "Round 65/200 completed.\n",
      " Avg Local Loss: 0.0508\n",
      " Global Loss: 1.9357, Accuracy: 62.16%\n",
      "Round 66/200 starting...\n",
      "Round 66/200 completed.\n",
      " Avg Local Loss: 0.0449\n",
      " Global Loss: 1.9044, Accuracy: 62.34%\n",
      "Round 67/200 starting...\n",
      "Round 67/200 completed.\n",
      " Avg Local Loss: 0.0404\n",
      " Global Loss: 2.0045, Accuracy: 61.98%\n",
      "Round 68/200 starting...\n",
      "Round 68/200 completed.\n",
      " Avg Local Loss: 0.0452\n",
      " Global Loss: 1.9370, Accuracy: 61.78%\n",
      "Round 69/200 starting...\n",
      "Round 69/200 completed.\n",
      " Avg Local Loss: 0.0259\n",
      " Global Loss: 1.8552, Accuracy: 63.51%\n",
      "Round 70/200 starting...\n",
      "Round 70/200 completed.\n",
      " Avg Local Loss: 0.0428\n",
      " Global Loss: 1.8867, Accuracy: 63.35%\n",
      "Round 71/200 starting...\n",
      "Round 71/200 completed.\n",
      " Avg Local Loss: 0.0439\n",
      " Global Loss: 1.9318, Accuracy: 61.81%\n",
      "Round 72/200 starting...\n",
      "Round 72/200 completed.\n",
      " Avg Local Loss: 0.0417\n",
      " Global Loss: 1.9678, Accuracy: 62.59%\n",
      "Round 73/200 starting...\n",
      "Round 73/200 completed.\n",
      " Avg Local Loss: 0.0414\n",
      " Global Loss: 1.8766, Accuracy: 62.99%\n",
      "Round 74/200 starting...\n",
      "Round 74/200 completed.\n",
      " Avg Local Loss: 0.0341\n",
      " Global Loss: 1.8963, Accuracy: 62.93%\n",
      "Round 75/200 starting...\n",
      "Round 75/200 completed.\n",
      " Avg Local Loss: 0.0421\n",
      " Global Loss: 1.8207, Accuracy: 63.38%\n",
      "Round 76/200 starting...\n",
      "Round 76/200 completed.\n",
      " Avg Local Loss: 0.0332\n",
      " Global Loss: 1.8891, Accuracy: 63.09%\n",
      "Round 77/200 starting...\n",
      "Round 77/200 completed.\n",
      " Avg Local Loss: 0.0483\n",
      " Global Loss: 1.9461, Accuracy: 62.95%\n",
      "Round 78/200 starting...\n",
      "Round 78/200 completed.\n",
      " Avg Local Loss: 0.0373\n",
      " Global Loss: 1.8736, Accuracy: 63.64%\n",
      "Round 79/200 starting...\n",
      "Round 79/200 completed.\n",
      " Avg Local Loss: 0.0307\n",
      " Global Loss: 1.9422, Accuracy: 62.34%\n",
      "Round 80/200 starting...\n",
      "Round 80/200 completed.\n",
      " Avg Local Loss: 0.0366\n",
      " Global Loss: 2.0318, Accuracy: 62.08%\n",
      "Round 81/200 starting...\n",
      "Round 81/200 completed.\n",
      " Avg Local Loss: 0.0433\n",
      " Global Loss: 1.8465, Accuracy: 63.35%\n",
      "Round 82/200 starting...\n",
      "Round 82/200 completed.\n",
      " Avg Local Loss: 0.0280\n",
      " Global Loss: 2.0839, Accuracy: 62.23%\n",
      "Round 83/200 starting...\n",
      "Round 83/200 completed.\n",
      " Avg Local Loss: 0.0300\n",
      " Global Loss: 1.9652, Accuracy: 62.74%\n",
      "Round 84/200 starting...\n",
      "Round 84/200 completed.\n",
      " Avg Local Loss: 0.0315\n",
      " Global Loss: 1.8947, Accuracy: 63.71%\n",
      "Round 85/200 starting...\n",
      "Round 85/200 completed.\n",
      " Avg Local Loss: 0.0390\n",
      " Global Loss: 1.9002, Accuracy: 63.17%\n",
      "Round 86/200 starting...\n",
      "Round 86/200 completed.\n",
      " Avg Local Loss: 0.0264\n",
      " Global Loss: 1.9625, Accuracy: 63.17%\n",
      "Round 87/200 starting...\n",
      "Round 87/200 completed.\n",
      " Avg Local Loss: 0.0368\n",
      " Global Loss: 2.0092, Accuracy: 62.37%\n",
      "Round 88/200 starting...\n",
      "Round 88/200 completed.\n",
      " Avg Local Loss: 0.0210\n",
      " Global Loss: 1.9691, Accuracy: 63.74%\n",
      "Round 89/200 starting...\n",
      "Round 89/200 completed.\n",
      " Avg Local Loss: 0.0323\n",
      " Global Loss: 2.0126, Accuracy: 62.61%\n",
      "Round 90/200 starting...\n",
      "Round 90/200 completed.\n",
      " Avg Local Loss: 0.0269\n",
      " Global Loss: 2.0067, Accuracy: 62.68%\n",
      "Round 91/200 starting...\n",
      "Round 91/200 completed.\n",
      " Avg Local Loss: 0.0242\n",
      " Global Loss: 2.0263, Accuracy: 63.11%\n",
      "Round 92/200 starting...\n",
      "Round 92/200 completed.\n",
      " Avg Local Loss: 0.0266\n",
      " Global Loss: 2.0529, Accuracy: 62.63%\n",
      "Round 93/200 starting...\n",
      "Round 93/200 completed.\n",
      " Avg Local Loss: 0.0299\n",
      " Global Loss: 2.0867, Accuracy: 62.81%\n",
      "Round 94/200 starting...\n",
      "Round 94/200 completed.\n",
      " Avg Local Loss: 0.0351\n",
      " Global Loss: 2.0649, Accuracy: 61.96%\n",
      "Round 95/200 starting...\n",
      "Round 95/200 completed.\n",
      " Avg Local Loss: 0.0115\n",
      " Global Loss: 2.0647, Accuracy: 62.44%\n",
      "Round 96/200 starting...\n",
      "Round 96/200 completed.\n",
      " Avg Local Loss: 0.0308\n",
      " Global Loss: 2.0542, Accuracy: 62.72%\n",
      "Round 97/200 starting...\n",
      "Round 97/200 completed.\n",
      " Avg Local Loss: 0.0259\n",
      " Global Loss: 1.9383, Accuracy: 63.61%\n",
      "Round 98/200 starting...\n",
      "Round 98/200 completed.\n",
      " Avg Local Loss: 0.0148\n",
      " Global Loss: 1.9997, Accuracy: 63.43%\n",
      "Round 99/200 starting...\n",
      "Round 99/200 completed.\n",
      " Avg Local Loss: 0.0320\n",
      " Global Loss: 2.0865, Accuracy: 62.90%\n",
      "Round 100/200 starting...\n",
      "Round 100/200 completed.\n",
      " Avg Local Loss: 0.0148\n",
      " Global Loss: 2.0685, Accuracy: 63.16%\n",
      "Round 101/200 starting...\n",
      "Round 101/200 completed.\n",
      " Avg Local Loss: 0.0279\n",
      " Global Loss: 2.0000, Accuracy: 63.47%\n",
      "Round 102/200 starting...\n",
      "Round 102/200 completed.\n",
      " Avg Local Loss: 0.0260\n",
      " Global Loss: 2.1851, Accuracy: 62.38%\n",
      "Round 103/200 starting...\n",
      "Round 103/200 completed.\n",
      " Avg Local Loss: 0.0253\n",
      " Global Loss: 2.1437, Accuracy: 62.20%\n",
      "Round 104/200 starting...\n",
      "Round 104/200 completed.\n",
      " Avg Local Loss: 0.0174\n",
      " Global Loss: 2.1656, Accuracy: 62.75%\n",
      "Round 105/200 starting...\n",
      "Round 105/200 completed.\n",
      " Avg Local Loss: 0.0182\n",
      " Global Loss: 2.1226, Accuracy: 63.21%\n",
      "Round 106/200 starting...\n",
      "Round 106/200 completed.\n",
      " Avg Local Loss: 0.0263\n",
      " Global Loss: 2.0279, Accuracy: 63.33%\n",
      "Round 107/200 starting...\n",
      "Round 107/200 completed.\n",
      " Avg Local Loss: 0.0116\n",
      " Global Loss: 2.2130, Accuracy: 62.87%\n",
      "Round 108/200 starting...\n",
      "Round 108/200 completed.\n",
      " Avg Local Loss: 0.0190\n",
      " Global Loss: 2.0956, Accuracy: 63.10%\n",
      "Round 109/200 starting...\n",
      "Round 109/200 completed.\n",
      " Avg Local Loss: 0.0230\n",
      " Global Loss: 2.2063, Accuracy: 62.20%\n",
      "Round 110/200 starting...\n",
      "Round 110/200 completed.\n",
      " Avg Local Loss: 0.0277\n",
      " Global Loss: 2.0818, Accuracy: 63.47%\n",
      "Round 111/200 starting...\n",
      "Round 111/200 completed.\n",
      " Avg Local Loss: 0.0166\n",
      " Global Loss: 2.0914, Accuracy: 63.53%\n",
      "Round 112/200 starting...\n",
      "Round 112/200 completed.\n",
      " Avg Local Loss: 0.0199\n",
      " Global Loss: 2.1132, Accuracy: 63.32%\n",
      "Round 113/200 starting...\n",
      "Round 113/200 completed.\n",
      " Avg Local Loss: 0.0220\n",
      " Global Loss: 2.1097, Accuracy: 62.86%\n",
      "Round 114/200 starting...\n",
      "Round 114/200 completed.\n",
      " Avg Local Loss: 0.0165\n",
      " Global Loss: 2.1048, Accuracy: 63.36%\n",
      "Round 115/200 starting...\n",
      "Round 115/200 completed.\n",
      " Avg Local Loss: 0.0267\n",
      " Global Loss: 2.2126, Accuracy: 62.59%\n",
      "Round 116/200 starting...\n",
      "Round 116/200 completed.\n",
      " Avg Local Loss: 0.0124\n",
      " Global Loss: 2.1825, Accuracy: 63.14%\n",
      "Round 117/200 starting...\n",
      "Round 117/200 completed.\n",
      " Avg Local Loss: 0.0126\n",
      " Global Loss: 2.1356, Accuracy: 63.16%\n",
      "Round 118/200 starting...\n",
      "Round 118/200 completed.\n",
      " Avg Local Loss: 0.0249\n",
      " Global Loss: 2.0714, Accuracy: 63.85%\n",
      "Round 119/200 starting...\n",
      "Round 119/200 completed.\n",
      " Avg Local Loss: 0.0220\n",
      " Global Loss: 2.0942, Accuracy: 63.54%\n",
      "Round 120/200 starting...\n",
      "Round 120/200 completed.\n",
      " Avg Local Loss: 0.0097\n",
      " Global Loss: 2.0996, Accuracy: 63.72%\n",
      "Round 121/200 starting...\n",
      "Round 121/200 completed.\n",
      " Avg Local Loss: 0.0221\n",
      " Global Loss: 2.1681, Accuracy: 63.08%\n",
      "Round 122/200 starting...\n",
      "Round 122/200 completed.\n",
      " Avg Local Loss: 0.0159\n",
      " Global Loss: 2.1884, Accuracy: 63.35%\n",
      "Round 123/200 starting...\n",
      "Round 123/200 completed.\n",
      " Avg Local Loss: 0.0231\n",
      " Global Loss: 2.1724, Accuracy: 63.01%\n",
      "Round 124/200 starting...\n",
      "Round 124/200 completed.\n",
      " Avg Local Loss: 0.0086\n",
      " Global Loss: 2.1181, Accuracy: 63.91%\n",
      "Round 125/200 starting...\n",
      "Round 125/200 completed.\n",
      " Avg Local Loss: 0.0098\n",
      " Global Loss: 2.2401, Accuracy: 63.40%\n",
      "Round 126/200 starting...\n",
      "Round 126/200 completed.\n",
      " Avg Local Loss: 0.0186\n",
      " Global Loss: 2.2818, Accuracy: 62.36%\n",
      "Round 127/200 starting...\n",
      "Round 127/200 completed.\n",
      " Avg Local Loss: 0.0160\n",
      " Global Loss: 2.1431, Accuracy: 63.39%\n",
      "Round 128/200 starting...\n",
      "Round 128/200 completed.\n",
      " Avg Local Loss: 0.0253\n",
      " Global Loss: 2.0588, Accuracy: 64.02%\n",
      "Round 129/200 starting...\n",
      "Round 129/200 completed.\n",
      " Avg Local Loss: 0.0118\n",
      " Global Loss: 2.2014, Accuracy: 63.59%\n",
      "Round 130/200 starting...\n",
      "Round 130/200 completed.\n",
      " Avg Local Loss: 0.0112\n",
      " Global Loss: 2.1878, Accuracy: 63.24%\n",
      "Round 131/200 starting...\n",
      "Round 131/200 completed.\n",
      " Avg Local Loss: 0.0159\n",
      " Global Loss: 2.1612, Accuracy: 63.66%\n",
      "Round 132/200 starting...\n",
      "Round 132/200 completed.\n",
      " Avg Local Loss: 0.0181\n",
      " Global Loss: 2.2052, Accuracy: 63.15%\n",
      "Round 133/200 starting...\n",
      "Round 133/200 completed.\n",
      " Avg Local Loss: 0.0314\n",
      " Global Loss: 2.1860, Accuracy: 63.07%\n",
      "Round 134/200 starting...\n",
      "Round 134/200 completed.\n",
      " Avg Local Loss: 0.0126\n",
      " Global Loss: 2.1827, Accuracy: 63.64%\n",
      "Round 135/200 starting...\n",
      "Round 135/200 completed.\n",
      " Avg Local Loss: 0.0138\n",
      " Global Loss: 2.2470, Accuracy: 63.02%\n",
      "Round 136/200 starting...\n",
      "Round 136/200 completed.\n",
      " Avg Local Loss: 0.0136\n",
      " Global Loss: 2.1865, Accuracy: 63.57%\n",
      "Round 137/200 starting...\n",
      "Round 137/200 completed.\n",
      " Avg Local Loss: 0.0165\n",
      " Global Loss: 2.2094, Accuracy: 63.26%\n",
      "Round 138/200 starting...\n",
      "Round 138/200 completed.\n",
      " Avg Local Loss: 0.0225\n",
      " Global Loss: 2.1618, Accuracy: 63.36%\n",
      "Round 139/200 starting...\n",
      "Round 139/200 completed.\n",
      " Avg Local Loss: 0.0101\n",
      " Global Loss: 2.2412, Accuracy: 63.52%\n",
      "Round 140/200 starting...\n",
      "Round 140/200 completed.\n",
      " Avg Local Loss: 0.0179\n",
      " Global Loss: 2.1810, Accuracy: 63.69%\n",
      "Round 141/200 starting...\n",
      "Round 141/200 completed.\n",
      " Avg Local Loss: 0.0089\n",
      " Global Loss: 2.1610, Accuracy: 63.90%\n",
      "Round 142/200 starting...\n",
      "Round 142/200 completed.\n",
      " Avg Local Loss: 0.0073\n",
      " Global Loss: 2.2505, Accuracy: 63.54%\n",
      "Round 143/200 starting...\n",
      "Round 143/200 completed.\n",
      " Avg Local Loss: 0.0094\n",
      " Global Loss: 2.2025, Accuracy: 63.62%\n",
      "Round 144/200 starting...\n",
      "Round 144/200 completed.\n",
      " Avg Local Loss: 0.0250\n",
      " Global Loss: 2.3153, Accuracy: 63.15%\n",
      "Round 145/200 starting...\n",
      "Round 145/200 completed.\n",
      " Avg Local Loss: 0.0090\n",
      " Global Loss: 2.2641, Accuracy: 63.47%\n",
      "Round 146/200 starting...\n",
      "Round 146/200 completed.\n",
      " Avg Local Loss: 0.0287\n",
      " Global Loss: 2.1354, Accuracy: 63.90%\n",
      "Round 147/200 starting...\n",
      "Round 147/200 completed.\n",
      " Avg Local Loss: 0.0074\n",
      " Global Loss: 2.3244, Accuracy: 62.77%\n",
      "Round 148/200 starting...\n",
      "Round 148/200 completed.\n",
      " Avg Local Loss: 0.0216\n",
      " Global Loss: 2.2799, Accuracy: 62.64%\n",
      "Round 149/200 starting...\n",
      "Round 149/200 completed.\n",
      " Avg Local Loss: 0.0132\n",
      " Global Loss: 2.1602, Accuracy: 63.91%\n",
      "Round 150/200 starting...\n",
      "Round 150/200 completed.\n",
      " Avg Local Loss: 0.0058\n",
      " Global Loss: 2.2420, Accuracy: 63.59%\n",
      "Round 151/200 starting...\n",
      "Round 151/200 completed.\n",
      " Avg Local Loss: 0.0115\n",
      " Global Loss: 2.1819, Accuracy: 64.22%\n",
      "Round 152/200 starting...\n",
      "Round 152/200 completed.\n",
      " Avg Local Loss: 0.0117\n",
      " Global Loss: 2.3228, Accuracy: 62.86%\n",
      "Round 153/200 starting...\n",
      "Round 153/200 completed.\n",
      " Avg Local Loss: 0.0173\n",
      " Global Loss: 2.2303, Accuracy: 63.56%\n",
      "Round 154/200 starting...\n",
      "Round 154/200 completed.\n",
      " Avg Local Loss: 0.0242\n",
      " Global Loss: 2.2823, Accuracy: 63.37%\n",
      "Round 155/200 starting...\n",
      "Round 155/200 completed.\n",
      " Avg Local Loss: 0.0063\n",
      " Global Loss: 2.2426, Accuracy: 64.24%\n",
      "Round 156/200 starting...\n",
      "Round 156/200 completed.\n",
      " Avg Local Loss: 0.0078\n",
      " Global Loss: 2.3097, Accuracy: 63.46%\n",
      "Round 157/200 starting...\n",
      "Round 157/200 completed.\n",
      " Avg Local Loss: 0.0241\n",
      " Global Loss: 2.2512, Accuracy: 63.32%\n",
      "Round 158/200 starting...\n",
      "Round 158/200 completed.\n",
      " Avg Local Loss: 0.0066\n",
      " Global Loss: 2.2852, Accuracy: 63.43%\n",
      "Round 159/200 starting...\n",
      "Round 159/200 completed.\n",
      " Avg Local Loss: 0.0105\n",
      " Global Loss: 2.3305, Accuracy: 63.24%\n",
      "Round 160/200 starting...\n",
      "Round 160/200 completed.\n",
      " Avg Local Loss: 0.0217\n",
      " Global Loss: 2.2331, Accuracy: 63.94%\n",
      "Round 161/200 starting...\n",
      "Round 161/200 completed.\n",
      " Avg Local Loss: 0.0088\n",
      " Global Loss: 2.2674, Accuracy: 63.48%\n",
      "Round 162/200 starting...\n",
      "Round 162/200 completed.\n",
      " Avg Local Loss: 0.0066\n",
      " Global Loss: 2.2553, Accuracy: 64.12%\n",
      "Round 163/200 starting...\n",
      "Round 163/200 completed.\n",
      " Avg Local Loss: 0.0154\n",
      " Global Loss: 2.3110, Accuracy: 63.90%\n",
      "Round 164/200 starting...\n",
      "Round 164/200 completed.\n",
      " Avg Local Loss: 0.0091\n",
      " Global Loss: 2.3236, Accuracy: 63.26%\n",
      "Round 165/200 starting...\n",
      "Round 165/200 completed.\n",
      " Avg Local Loss: 0.0233\n",
      " Global Loss: 2.2978, Accuracy: 63.23%\n",
      "Round 166/200 starting...\n",
      "Round 166/200 completed.\n",
      " Avg Local Loss: 0.0068\n",
      " Global Loss: 2.3691, Accuracy: 62.91%\n",
      "Round 167/200 starting...\n",
      "Round 167/200 completed.\n",
      " Avg Local Loss: 0.0090\n",
      " Global Loss: 2.2643, Accuracy: 64.17%\n",
      "Round 168/200 starting...\n",
      "Round 168/200 completed.\n",
      " Avg Local Loss: 0.0057\n",
      " Global Loss: 2.3560, Accuracy: 63.24%\n",
      "Round 169/200 starting...\n",
      "Round 169/200 completed.\n",
      " Avg Local Loss: 0.0140\n",
      " Global Loss: 2.2774, Accuracy: 63.79%\n",
      "Round 170/200 starting...\n",
      "Round 170/200 completed.\n",
      " Avg Local Loss: 0.0076\n",
      " Global Loss: 2.4176, Accuracy: 63.20%\n",
      "Round 171/200 starting...\n",
      "Round 171/200 completed.\n",
      " Avg Local Loss: 0.0226\n",
      " Global Loss: 2.2462, Accuracy: 63.08%\n",
      "Round 172/200 starting...\n",
      "Round 172/200 completed.\n",
      " Avg Local Loss: 0.0074\n",
      " Global Loss: 2.3652, Accuracy: 63.23%\n",
      "Round 173/200 starting...\n",
      "Round 173/200 completed.\n",
      " Avg Local Loss: 0.0085\n",
      " Global Loss: 2.2755, Accuracy: 63.90%\n",
      "Round 174/200 starting...\n",
      "Round 174/200 completed.\n",
      " Avg Local Loss: 0.0046\n",
      " Global Loss: 2.2944, Accuracy: 64.00%\n",
      "Round 175/200 starting...\n",
      "Round 175/200 completed.\n",
      " Avg Local Loss: 0.0095\n",
      " Global Loss: 2.4483, Accuracy: 63.22%\n",
      "Round 176/200 starting...\n",
      "Round 176/200 completed.\n",
      " Avg Local Loss: 0.0312\n",
      " Global Loss: 2.3324, Accuracy: 63.07%\n",
      "Round 177/200 starting...\n",
      "Round 177/200 completed.\n",
      " Avg Local Loss: 0.0067\n",
      " Global Loss: 2.2893, Accuracy: 63.47%\n",
      "Round 178/200 starting...\n",
      "Round 178/200 completed.\n",
      " Avg Local Loss: 0.0082\n",
      " Global Loss: 2.3804, Accuracy: 63.51%\n",
      "Round 179/200 starting...\n",
      "Round 179/200 completed.\n",
      " Avg Local Loss: 0.0068\n",
      " Global Loss: 2.3925, Accuracy: 63.13%\n",
      "Round 180/200 starting...\n",
      "Round 180/200 completed.\n",
      " Avg Local Loss: 0.0105\n",
      " Global Loss: 2.3107, Accuracy: 63.60%\n",
      "Round 181/200 starting...\n",
      "Round 181/200 completed.\n",
      " Avg Local Loss: 0.0053\n",
      " Global Loss: 2.3053, Accuracy: 63.96%\n",
      "Round 182/200 starting...\n",
      "Round 182/200 completed.\n",
      " Avg Local Loss: 0.0061\n",
      " Global Loss: 2.3904, Accuracy: 63.01%\n",
      "Round 183/200 starting...\n",
      "Round 183/200 completed.\n",
      " Avg Local Loss: 0.0050\n",
      " Global Loss: 2.4464, Accuracy: 63.13%\n",
      "Round 184/200 starting...\n",
      "Round 184/200 completed.\n",
      " Avg Local Loss: 0.0385\n",
      " Global Loss: 2.2515, Accuracy: 63.72%\n",
      "Round 185/200 starting...\n",
      "Round 185/200 completed.\n",
      " Avg Local Loss: 0.0060\n",
      " Global Loss: 2.2740, Accuracy: 64.22%\n",
      "Round 186/200 starting...\n",
      "Round 186/200 completed.\n",
      " Avg Local Loss: 0.0113\n",
      " Global Loss: 2.2889, Accuracy: 63.85%\n",
      "Round 187/200 starting...\n",
      "Round 187/200 completed.\n",
      " Avg Local Loss: 0.0070\n",
      " Global Loss: 2.3639, Accuracy: 63.75%\n",
      "Round 188/200 starting...\n",
      "Round 188/200 completed.\n",
      " Avg Local Loss: 0.0073\n",
      " Global Loss: 2.3642, Accuracy: 63.64%\n",
      "Round 189/200 starting...\n",
      "Round 189/200 completed.\n",
      " Avg Local Loss: 0.0199\n",
      " Global Loss: 2.3860, Accuracy: 63.00%\n",
      "Round 190/200 starting...\n",
      "Round 190/200 completed.\n",
      " Avg Local Loss: 0.0046\n",
      " Global Loss: 2.3557, Accuracy: 63.58%\n",
      "Round 191/200 starting...\n",
      "Round 191/200 completed.\n",
      " Avg Local Loss: 0.0035\n",
      " Global Loss: 2.3677, Accuracy: 63.75%\n",
      "Round 192/200 starting...\n",
      "Round 192/200 completed.\n",
      " Avg Local Loss: 0.0051\n",
      " Global Loss: 2.4004, Accuracy: 63.59%\n",
      "Round 193/200 starting...\n",
      "Round 193/200 completed.\n",
      " Avg Local Loss: 0.0063\n",
      " Global Loss: 2.3981, Accuracy: 63.81%\n",
      "Round 194/200 starting...\n",
      "Round 194/200 completed.\n",
      " Avg Local Loss: 0.0098\n",
      " Global Loss: 2.3458, Accuracy: 64.12%\n",
      "Round 195/200 starting...\n",
      "Round 195/200 completed.\n",
      " Avg Local Loss: 0.0053\n",
      " Global Loss: 2.3449, Accuracy: 64.28%\n",
      "Round 196/200 starting...\n",
      "Round 196/200 completed.\n",
      " Avg Local Loss: 0.0340\n",
      " Global Loss: 2.2910, Accuracy: 63.59%\n",
      "Round 197/200 starting...\n",
      "Round 197/200 completed.\n",
      " Avg Local Loss: 0.0055\n",
      " Global Loss: 2.3735, Accuracy: 63.40%\n",
      "Round 198/200 starting...\n",
      "Round 198/200 completed.\n",
      " Avg Local Loss: 0.0066\n",
      " Global Loss: 2.4343, Accuracy: 62.88%\n",
      "Round 199/200 starting...\n",
      "Round 199/200 completed.\n",
      " Avg Local Loss: 0.0056\n",
      " Global Loss: 2.4028, Accuracy: 64.04%\n",
      "Round 200/200 starting...\n",
      "Round 200/200 completed.\n",
      " Avg Local Loss: 0.0058\n",
      " Global Loss: 2.4943, Accuracy: 63.04%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "momentum = 0\n",
    "mu = 0.1\n",
    "method = 'FedProx'\n",
    "\n",
    "federated_learning_with_scenario(server_class=Server, user_class=User, global_model_class=SimpleCNN, dataset=cifar10_train, test_loader=test_loader,\n",
    "        num_users=num_users,\n",
    "        rounds=rounds,\n",
    "        epochs=epochs,\n",
    "        fraction=fraction,\n",
    "        iid=iid,\n",
    "        lr=learning_rate,\n",
    "        alpha=alpha,\n",
    "        method=method,\n",
    "        momentum=momentum,\n",
    "        mu=mu,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "z0jrpzS3ND4Z",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: Non-IID with 20 users (alpha=0.5).\n",
      "Round 1/200 starting...\n",
      "Round 1/200 completed.\n",
      " Avg Local Loss: 1.5947\n",
      " Global Loss: 2.1825, Accuracy: 21.14%\n",
      "Round 2/200 starting...\n",
      "Round 2/200 completed.\n",
      " Avg Local Loss: 1.4982\n",
      " Global Loss: 1.8738, Accuracy: 32.38%\n",
      "Round 3/200 starting...\n",
      "Round 3/200 completed.\n",
      " Avg Local Loss: 1.3265\n",
      " Global Loss: 1.7501, Accuracy: 35.79%\n",
      "Round 4/200 starting...\n",
      "Round 4/200 completed.\n",
      " Avg Local Loss: 1.2061\n",
      " Global Loss: 1.6226, Accuracy: 41.29%\n",
      "Round 5/200 starting...\n",
      "Round 5/200 completed.\n",
      " Avg Local Loss: 1.1866\n",
      " Global Loss: 1.5286, Accuracy: 45.58%\n",
      "Round 6/200 starting...\n",
      "Round 6/200 completed.\n",
      " Avg Local Loss: 1.1498\n",
      " Global Loss: 1.5172, Accuracy: 46.07%\n",
      "Round 7/200 starting...\n",
      "Round 7/200 completed.\n",
      " Avg Local Loss: 1.0214\n",
      " Global Loss: 1.4465, Accuracy: 49.17%\n",
      "Round 8/200 starting...\n",
      "Round 8/200 completed.\n",
      " Avg Local Loss: 1.0016\n",
      " Global Loss: 1.4067, Accuracy: 50.10%\n",
      "Round 9/200 starting...\n",
      "Round 9/200 completed.\n",
      " Avg Local Loss: 0.9183\n",
      " Global Loss: 1.3173, Accuracy: 52.82%\n",
      "Round 10/200 starting...\n",
      "Round 10/200 completed.\n",
      " Avg Local Loss: 0.8917\n",
      " Global Loss: 1.4261, Accuracy: 49.13%\n",
      "Round 11/200 starting...\n",
      "Round 11/200 completed.\n",
      " Avg Local Loss: 0.8222\n",
      " Global Loss: 1.3425, Accuracy: 53.22%\n",
      "Round 12/200 starting...\n",
      "Round 12/200 completed.\n",
      " Avg Local Loss: 0.8034\n",
      " Global Loss: 1.3070, Accuracy: 52.83%\n",
      "Round 13/200 starting...\n",
      "Round 13/200 completed.\n",
      " Avg Local Loss: 0.8709\n",
      " Global Loss: 1.2584, Accuracy: 54.50%\n",
      "Round 14/200 starting...\n",
      "Round 14/200 completed.\n",
      " Avg Local Loss: 0.8246\n",
      " Global Loss: 1.2251, Accuracy: 56.25%\n",
      "Round 15/200 starting...\n",
      "Round 15/200 completed.\n",
      " Avg Local Loss: 0.6936\n",
      " Global Loss: 1.2390, Accuracy: 56.07%\n",
      "Round 16/200 starting...\n",
      "Round 16/200 completed.\n",
      " Avg Local Loss: 0.7856\n",
      " Global Loss: 1.1991, Accuracy: 57.03%\n",
      "Round 17/200 starting...\n",
      "Round 17/200 completed.\n",
      " Avg Local Loss: 0.6778\n",
      " Global Loss: 1.1629, Accuracy: 58.95%\n",
      "Round 18/200 starting...\n",
      "Round 18/200 completed.\n",
      " Avg Local Loss: 0.7602\n",
      " Global Loss: 1.1687, Accuracy: 58.39%\n",
      "Round 19/200 starting...\n",
      "Round 19/200 completed.\n",
      " Avg Local Loss: 0.5979\n",
      " Global Loss: 1.1663, Accuracy: 58.65%\n",
      "Round 20/200 starting...\n",
      "Round 20/200 completed.\n",
      " Avg Local Loss: 0.6079\n",
      " Global Loss: 1.1199, Accuracy: 60.32%\n",
      "Round 21/200 starting...\n",
      "Round 21/200 completed.\n",
      " Avg Local Loss: 0.5821\n",
      " Global Loss: 1.2213, Accuracy: 58.09%\n",
      "Round 22/200 starting...\n",
      "Round 22/200 completed.\n",
      " Avg Local Loss: 0.6288\n",
      " Global Loss: 1.1072, Accuracy: 61.30%\n",
      "Round 23/200 starting...\n",
      "Round 23/200 completed.\n",
      " Avg Local Loss: 0.6077\n",
      " Global Loss: 1.1299, Accuracy: 61.63%\n",
      "Round 24/200 starting...\n",
      "Round 24/200 completed.\n",
      " Avg Local Loss: 0.5192\n",
      " Global Loss: 1.0939, Accuracy: 62.69%\n",
      "Round 25/200 starting...\n",
      "Round 25/200 completed.\n",
      " Avg Local Loss: 0.4968\n",
      " Global Loss: 1.1367, Accuracy: 61.65%\n",
      "Round 26/200 starting...\n",
      "Round 26/200 completed.\n",
      " Avg Local Loss: 0.4540\n",
      " Global Loss: 1.0307, Accuracy: 64.40%\n",
      "Round 27/200 starting...\n",
      "Round 27/200 completed.\n",
      " Avg Local Loss: 0.4681\n",
      " Global Loss: 1.0848, Accuracy: 63.72%\n",
      "Round 28/200 starting...\n",
      "Round 28/200 completed.\n",
      " Avg Local Loss: 0.3630\n",
      " Global Loss: 1.2680, Accuracy: 59.77%\n",
      "Round 29/200 starting...\n",
      "Round 29/200 completed.\n",
      " Avg Local Loss: 0.3964\n",
      " Global Loss: 1.0724, Accuracy: 64.85%\n",
      "Round 30/200 starting...\n",
      "Round 30/200 completed.\n",
      " Avg Local Loss: 0.3358\n",
      " Global Loss: 1.0761, Accuracy: 64.92%\n",
      "Round 31/200 starting...\n",
      "Round 31/200 completed.\n",
      " Avg Local Loss: 0.3201\n",
      " Global Loss: 1.0849, Accuracy: 65.46%\n",
      "Round 32/200 starting...\n",
      "Round 32/200 completed.\n",
      " Avg Local Loss: 0.3353\n",
      " Global Loss: 1.0816, Accuracy: 65.73%\n",
      "Round 33/200 starting...\n",
      "Round 33/200 completed.\n",
      " Avg Local Loss: 0.2960\n",
      " Global Loss: 1.0926, Accuracy: 65.18%\n",
      "Round 34/200 starting...\n",
      "Round 34/200 completed.\n",
      " Avg Local Loss: 0.2531\n",
      " Global Loss: 1.1661, Accuracy: 64.28%\n",
      "Round 35/200 starting...\n",
      "Round 35/200 completed.\n",
      " Avg Local Loss: 0.2670\n",
      " Global Loss: 1.1181, Accuracy: 65.31%\n",
      "Round 36/200 starting...\n",
      "Round 36/200 completed.\n",
      " Avg Local Loss: 0.2567\n",
      " Global Loss: 1.0887, Accuracy: 66.62%\n",
      "Round 37/200 starting...\n",
      "Round 37/200 completed.\n",
      " Avg Local Loss: 0.2143\n",
      " Global Loss: 1.1870, Accuracy: 64.37%\n",
      "Round 38/200 starting...\n",
      "Round 38/200 completed.\n",
      " Avg Local Loss: 0.2271\n",
      " Global Loss: 1.0917, Accuracy: 66.72%\n",
      "Round 39/200 starting...\n",
      "Round 39/200 completed.\n",
      " Avg Local Loss: 0.2485\n",
      " Global Loss: 1.1828, Accuracy: 65.65%\n",
      "Round 40/200 starting...\n",
      "Round 40/200 completed.\n",
      " Avg Local Loss: 0.2055\n",
      " Global Loss: 1.1768, Accuracy: 65.59%\n",
      "Round 41/200 starting...\n",
      "Round 41/200 completed.\n",
      " Avg Local Loss: 0.1736\n",
      " Global Loss: 1.2017, Accuracy: 65.38%\n",
      "Round 42/200 starting...\n",
      "Round 42/200 completed.\n",
      " Avg Local Loss: 0.1854\n",
      " Global Loss: 1.1640, Accuracy: 65.89%\n",
      "Round 43/200 starting...\n",
      "Round 43/200 completed.\n",
      " Avg Local Loss: 0.1851\n",
      " Global Loss: 1.2040, Accuracy: 65.90%\n",
      "Round 44/200 starting...\n",
      "Round 44/200 completed.\n",
      " Avg Local Loss: 0.1703\n",
      " Global Loss: 1.1328, Accuracy: 67.57%\n",
      "Round 45/200 starting...\n",
      "Round 45/200 completed.\n",
      " Avg Local Loss: 0.1380\n",
      " Global Loss: 1.2648, Accuracy: 65.45%\n",
      "Round 46/200 starting...\n",
      "Round 46/200 completed.\n",
      " Avg Local Loss: 0.1420\n",
      " Global Loss: 1.2664, Accuracy: 65.31%\n",
      "Round 47/200 starting...\n",
      "Round 47/200 completed.\n",
      " Avg Local Loss: 0.1591\n",
      " Global Loss: 1.1645, Accuracy: 67.02%\n",
      "Round 48/200 starting...\n",
      "Round 48/200 completed.\n",
      " Avg Local Loss: 0.1259\n",
      " Global Loss: 1.2073, Accuracy: 66.72%\n",
      "Round 49/200 starting...\n",
      "Round 49/200 completed.\n",
      " Avg Local Loss: 0.1330\n",
      " Global Loss: 1.2615, Accuracy: 66.30%\n",
      "Round 50/200 starting...\n",
      "Round 50/200 completed.\n",
      " Avg Local Loss: 0.1439\n",
      " Global Loss: 1.2693, Accuracy: 66.14%\n",
      "Round 51/200 starting...\n",
      "Round 51/200 completed.\n",
      " Avg Local Loss: 0.1174\n",
      " Global Loss: 1.2915, Accuracy: 65.89%\n",
      "Round 52/200 starting...\n",
      "Round 52/200 completed.\n",
      " Avg Local Loss: 0.1279\n",
      " Global Loss: 1.2354, Accuracy: 67.07%\n",
      "Round 53/200 starting...\n",
      "Round 53/200 completed.\n",
      " Avg Local Loss: 0.1180\n",
      " Global Loss: 1.2796, Accuracy: 66.48%\n",
      "Round 54/200 starting...\n",
      "Round 54/200 completed.\n",
      " Avg Local Loss: 0.1111\n",
      " Global Loss: 1.2606, Accuracy: 67.29%\n",
      "Round 55/200 starting...\n",
      "Round 55/200 completed.\n",
      " Avg Local Loss: 0.1093\n",
      " Global Loss: 1.3023, Accuracy: 66.04%\n",
      "Round 56/200 starting...\n",
      "Round 56/200 completed.\n",
      " Avg Local Loss: 0.0936\n",
      " Global Loss: 1.2982, Accuracy: 67.08%\n",
      "Round 57/200 starting...\n",
      "Round 57/200 completed.\n",
      " Avg Local Loss: 0.0918\n",
      " Global Loss: 1.2808, Accuracy: 67.15%\n",
      "Round 58/200 starting...\n",
      "Round 58/200 completed.\n",
      " Avg Local Loss: 0.1011\n",
      " Global Loss: 1.3040, Accuracy: 67.11%\n",
      "Round 59/200 starting...\n",
      "Round 59/200 completed.\n",
      " Avg Local Loss: 0.0835\n",
      " Global Loss: 1.3345, Accuracy: 67.35%\n",
      "Round 60/200 starting...\n",
      "Round 60/200 completed.\n",
      " Avg Local Loss: 0.0889\n",
      " Global Loss: 1.3460, Accuracy: 67.34%\n",
      "Round 61/200 starting...\n",
      "Round 61/200 completed.\n",
      " Avg Local Loss: 0.0830\n",
      " Global Loss: 1.4498, Accuracy: 65.10%\n",
      "Round 62/200 starting...\n",
      "Round 62/200 completed.\n",
      " Avg Local Loss: 0.0630\n",
      " Global Loss: 1.4936, Accuracy: 64.59%\n",
      "Round 63/200 starting...\n",
      "Round 63/200 completed.\n",
      " Avg Local Loss: 0.0889\n",
      " Global Loss: 1.3651, Accuracy: 66.36%\n",
      "Round 64/200 starting...\n",
      "Round 64/200 completed.\n",
      " Avg Local Loss: 0.0667\n",
      " Global Loss: 1.3310, Accuracy: 67.89%\n",
      "Round 65/200 starting...\n",
      "Round 65/200 completed.\n",
      " Avg Local Loss: 0.0863\n",
      " Global Loss: 1.3163, Accuracy: 67.62%\n",
      "Round 66/200 starting...\n",
      "Round 66/200 completed.\n",
      " Avg Local Loss: 0.0932\n",
      " Global Loss: 1.3358, Accuracy: 67.34%\n",
      "Round 67/200 starting...\n",
      "Round 67/200 completed.\n",
      " Avg Local Loss: 0.0469\n",
      " Global Loss: 1.4003, Accuracy: 66.85%\n",
      "Round 68/200 starting...\n",
      "Round 68/200 completed.\n",
      " Avg Local Loss: 0.0786\n",
      " Global Loss: 1.4234, Accuracy: 66.45%\n",
      "Round 69/200 starting...\n",
      "Round 69/200 completed.\n",
      " Avg Local Loss: 0.0751\n",
      " Global Loss: 1.4954, Accuracy: 65.51%\n",
      "Round 70/200 starting...\n",
      "Round 70/200 completed.\n",
      " Avg Local Loss: 0.0572\n",
      " Global Loss: 1.4255, Accuracy: 67.03%\n",
      "Round 71/200 starting...\n",
      "Round 71/200 completed.\n",
      " Avg Local Loss: 0.0579\n",
      " Global Loss: 1.3961, Accuracy: 66.69%\n",
      "Round 72/200 starting...\n",
      "Round 72/200 completed.\n",
      " Avg Local Loss: 0.1167\n",
      " Global Loss: 1.2949, Accuracy: 67.29%\n",
      "Round 73/200 starting...\n",
      "Round 73/200 completed.\n",
      " Avg Local Loss: 0.0444\n",
      " Global Loss: 1.3715, Accuracy: 66.80%\n",
      "Round 74/200 starting...\n",
      "Round 74/200 completed.\n",
      " Avg Local Loss: 0.0469\n",
      " Global Loss: 1.4140, Accuracy: 66.79%\n",
      "Round 75/200 starting...\n",
      "Round 75/200 completed.\n",
      " Avg Local Loss: 0.0729\n",
      " Global Loss: 1.3310, Accuracy: 68.34%\n",
      "Round 76/200 starting...\n",
      "Round 76/200 completed.\n",
      " Avg Local Loss: 0.0473\n",
      " Global Loss: 1.3687, Accuracy: 67.81%\n",
      "Round 77/200 starting...\n",
      "Round 77/200 completed.\n",
      " Avg Local Loss: 0.0549\n",
      " Global Loss: 1.3606, Accuracy: 68.22%\n",
      "Round 78/200 starting...\n",
      "Round 78/200 completed.\n",
      " Avg Local Loss: 0.1484\n",
      " Global Loss: 1.3932, Accuracy: 66.67%\n",
      "Round 79/200 starting...\n",
      "Round 79/200 completed.\n",
      " Avg Local Loss: 0.0483\n",
      " Global Loss: 1.4005, Accuracy: 67.06%\n",
      "Round 80/200 starting...\n",
      "Round 80/200 completed.\n",
      " Avg Local Loss: 0.0384\n",
      " Global Loss: 1.4652, Accuracy: 66.72%\n",
      "Round 81/200 starting...\n",
      "Round 81/200 completed.\n",
      " Avg Local Loss: 0.0379\n",
      " Global Loss: 1.4029, Accuracy: 67.60%\n",
      "Round 82/200 starting...\n",
      "Round 82/200 completed.\n",
      " Avg Local Loss: 0.0353\n",
      " Global Loss: 1.4468, Accuracy: 67.36%\n",
      "Round 83/200 starting...\n",
      "Round 83/200 completed.\n",
      " Avg Local Loss: 0.0483\n",
      " Global Loss: 1.4786, Accuracy: 66.63%\n",
      "Round 84/200 starting...\n",
      "Round 84/200 completed.\n",
      " Avg Local Loss: 0.0337\n",
      " Global Loss: 1.4245, Accuracy: 67.74%\n",
      "Round 85/200 starting...\n",
      "Round 85/200 completed.\n",
      " Avg Local Loss: 0.0392\n",
      " Global Loss: 1.4889, Accuracy: 67.48%\n",
      "Round 86/200 starting...\n",
      "Round 86/200 completed.\n",
      " Avg Local Loss: 0.0289\n",
      " Global Loss: 1.6433, Accuracy: 65.64%\n",
      "Round 87/200 starting...\n",
      "Round 87/200 completed.\n",
      " Avg Local Loss: 0.0490\n",
      " Global Loss: 1.4451, Accuracy: 67.08%\n",
      "Round 88/200 starting...\n",
      "Round 88/200 completed.\n",
      " Avg Local Loss: 0.0246\n",
      " Global Loss: 1.4419, Accuracy: 67.93%\n",
      "Round 89/200 starting...\n",
      "Round 89/200 completed.\n",
      " Avg Local Loss: 0.0259\n",
      " Global Loss: 1.4523, Accuracy: 68.23%\n",
      "Round 90/200 starting...\n",
      "Round 90/200 completed.\n",
      " Avg Local Loss: 0.0281\n",
      " Global Loss: 1.5564, Accuracy: 66.60%\n",
      "Round 91/200 starting...\n",
      "Round 91/200 completed.\n",
      " Avg Local Loss: 0.0325\n",
      " Global Loss: 1.5717, Accuracy: 66.55%\n",
      "Round 92/200 starting...\n",
      "Round 92/200 completed.\n",
      " Avg Local Loss: 0.0296\n",
      " Global Loss: 1.5065, Accuracy: 67.11%\n",
      "Round 93/200 starting...\n",
      "Round 93/200 completed.\n",
      " Avg Local Loss: 0.0441\n",
      " Global Loss: 1.4814, Accuracy: 67.36%\n",
      "Round 94/200 starting...\n",
      "Round 94/200 completed.\n",
      " Avg Local Loss: 0.0311\n",
      " Global Loss: 1.5867, Accuracy: 66.14%\n",
      "Round 95/200 starting...\n",
      "Round 95/200 completed.\n",
      " Avg Local Loss: 0.0226\n",
      " Global Loss: 1.4700, Accuracy: 67.55%\n",
      "Round 96/200 starting...\n",
      "Round 96/200 completed.\n",
      " Avg Local Loss: 0.0184\n",
      " Global Loss: 1.5251, Accuracy: 67.87%\n",
      "Round 97/200 starting...\n",
      "Round 97/200 completed.\n",
      " Avg Local Loss: 0.0276\n",
      " Global Loss: 1.5768, Accuracy: 66.50%\n",
      "Round 98/200 starting...\n",
      "Round 98/200 completed.\n",
      " Avg Local Loss: 0.0291\n",
      " Global Loss: 1.4820, Accuracy: 67.83%\n",
      "Round 99/200 starting...\n",
      "Round 99/200 completed.\n",
      " Avg Local Loss: 0.0198\n",
      " Global Loss: 1.4902, Accuracy: 68.00%\n",
      "Round 100/200 starting...\n",
      "Round 100/200 completed.\n",
      " Avg Local Loss: 0.0365\n",
      " Global Loss: 1.4830, Accuracy: 68.07%\n",
      "Round 101/200 starting...\n",
      "Round 101/200 completed.\n",
      " Avg Local Loss: 0.0281\n",
      " Global Loss: 1.6016, Accuracy: 66.68%\n",
      "Round 102/200 starting...\n",
      "Round 102/200 completed.\n",
      " Avg Local Loss: 0.0261\n",
      " Global Loss: 1.5189, Accuracy: 67.55%\n",
      "Round 103/200 starting...\n",
      "Round 103/200 completed.\n",
      " Avg Local Loss: 0.0208\n",
      " Global Loss: 1.5387, Accuracy: 67.71%\n",
      "Round 104/200 starting...\n",
      "Round 104/200 completed.\n",
      " Avg Local Loss: 0.0320\n",
      " Global Loss: 1.5475, Accuracy: 67.49%\n",
      "Round 105/200 starting...\n",
      "Round 105/200 completed.\n",
      " Avg Local Loss: 0.0235\n",
      " Global Loss: 1.5211, Accuracy: 68.16%\n",
      "Round 106/200 starting...\n",
      "Round 106/200 completed.\n",
      " Avg Local Loss: 0.0242\n",
      " Global Loss: 1.5951, Accuracy: 67.05%\n",
      "Round 107/200 starting...\n",
      "Round 107/200 completed.\n",
      " Avg Local Loss: 0.0282\n",
      " Global Loss: 1.5493, Accuracy: 66.86%\n",
      "Round 108/200 starting...\n",
      "Round 108/200 completed.\n",
      " Avg Local Loss: 0.0121\n",
      " Global Loss: 1.6476, Accuracy: 66.69%\n",
      "Round 109/200 starting...\n",
      "Round 109/200 completed.\n",
      " Avg Local Loss: 0.0271\n",
      " Global Loss: 1.6113, Accuracy: 66.84%\n",
      "Round 110/200 starting...\n",
      "Round 110/200 completed.\n",
      " Avg Local Loss: 0.0154\n",
      " Global Loss: 1.5971, Accuracy: 67.18%\n",
      "Round 111/200 starting...\n",
      "Round 111/200 completed.\n",
      " Avg Local Loss: 0.0111\n",
      " Global Loss: 1.6475, Accuracy: 66.69%\n",
      "Round 112/200 starting...\n",
      "Round 112/200 completed.\n",
      " Avg Local Loss: 0.0160\n",
      " Global Loss: 1.6054, Accuracy: 67.41%\n",
      "Round 113/200 starting...\n",
      "Round 113/200 completed.\n",
      " Avg Local Loss: 0.0121\n",
      " Global Loss: 1.6306, Accuracy: 67.02%\n",
      "Round 114/200 starting...\n",
      "Round 114/200 completed.\n",
      " Avg Local Loss: 0.0202\n",
      " Global Loss: 1.6685, Accuracy: 66.78%\n",
      "Round 115/200 starting...\n",
      "Round 115/200 completed.\n",
      " Avg Local Loss: 0.0145\n",
      " Global Loss: 1.6668, Accuracy: 66.75%\n",
      "Round 116/200 starting...\n",
      "Round 116/200 completed.\n",
      " Avg Local Loss: 0.0155\n",
      " Global Loss: 1.6254, Accuracy: 67.05%\n",
      "Round 117/200 starting...\n",
      "Round 117/200 completed.\n",
      " Avg Local Loss: 0.0258\n",
      " Global Loss: 1.7730, Accuracy: 65.34%\n",
      "Round 118/200 starting...\n",
      "Round 118/200 completed.\n",
      " Avg Local Loss: 0.0208\n",
      " Global Loss: 1.6031, Accuracy: 67.63%\n",
      "Round 119/200 starting...\n",
      "Round 119/200 completed.\n",
      " Avg Local Loss: 0.0194\n",
      " Global Loss: 1.6471, Accuracy: 67.05%\n",
      "Round 120/200 starting...\n",
      "Round 120/200 completed.\n",
      " Avg Local Loss: 0.0284\n",
      " Global Loss: 1.5551, Accuracy: 68.08%\n",
      "Round 121/200 starting...\n",
      "Round 121/200 completed.\n",
      " Avg Local Loss: 0.0113\n",
      " Global Loss: 1.6632, Accuracy: 67.03%\n",
      "Round 122/200 starting...\n",
      "Round 122/200 completed.\n",
      " Avg Local Loss: 0.0144\n",
      " Global Loss: 1.6416, Accuracy: 67.27%\n",
      "Round 123/200 starting...\n",
      "Round 123/200 completed.\n",
      " Avg Local Loss: 0.0114\n",
      " Global Loss: 1.6243, Accuracy: 67.46%\n",
      "Round 124/200 starting...\n",
      "Round 124/200 completed.\n",
      " Avg Local Loss: 0.0121\n",
      " Global Loss: 1.7955, Accuracy: 65.61%\n",
      "Round 125/200 starting...\n",
      "Round 125/200 completed.\n",
      " Avg Local Loss: 0.0158\n",
      " Global Loss: 1.6197, Accuracy: 67.80%\n",
      "Round 126/200 starting...\n",
      "Round 126/200 completed.\n",
      " Avg Local Loss: 0.0119\n",
      " Global Loss: 1.8044, Accuracy: 65.98%\n",
      "Round 127/200 starting...\n",
      "Round 127/200 completed.\n",
      " Avg Local Loss: 0.0160\n",
      " Global Loss: 1.6601, Accuracy: 67.71%\n",
      "Round 128/200 starting...\n",
      "Round 128/200 completed.\n",
      " Avg Local Loss: 0.0154\n",
      " Global Loss: 1.6626, Accuracy: 67.46%\n",
      "Round 129/200 starting...\n",
      "Round 129/200 completed.\n",
      " Avg Local Loss: 0.0070\n",
      " Global Loss: 1.6925, Accuracy: 67.26%\n",
      "Round 130/200 starting...\n",
      "Round 130/200 completed.\n",
      " Avg Local Loss: 0.0166\n",
      " Global Loss: 1.6493, Accuracy: 68.14%\n",
      "Round 131/200 starting...\n",
      "Round 131/200 completed.\n",
      " Avg Local Loss: 0.0123\n",
      " Global Loss: 1.6129, Accuracy: 68.21%\n",
      "Round 132/200 starting...\n",
      "Round 132/200 completed.\n",
      " Avg Local Loss: 0.0173\n",
      " Global Loss: 1.6581, Accuracy: 67.79%\n",
      "Round 133/200 starting...\n",
      "Round 133/200 completed.\n",
      " Avg Local Loss: 0.0104\n",
      " Global Loss: 1.6964, Accuracy: 67.60%\n",
      "Round 134/200 starting...\n",
      "Round 134/200 completed.\n",
      " Avg Local Loss: 0.0114\n",
      " Global Loss: 1.6851, Accuracy: 67.31%\n",
      "Round 135/200 starting...\n",
      "Round 135/200 completed.\n",
      " Avg Local Loss: 0.0175\n",
      " Global Loss: 1.6253, Accuracy: 68.05%\n",
      "Round 136/200 starting...\n",
      "Round 136/200 completed.\n",
      " Avg Local Loss: 0.0071\n",
      " Global Loss: 1.7110, Accuracy: 67.46%\n",
      "Round 137/200 starting...\n",
      "Round 137/200 completed.\n",
      " Avg Local Loss: 0.0070\n",
      " Global Loss: 1.7302, Accuracy: 67.41%\n",
      "Round 138/200 starting...\n",
      "Round 138/200 completed.\n",
      " Avg Local Loss: 0.0148\n",
      " Global Loss: 1.6397, Accuracy: 68.15%\n",
      "Round 139/200 starting...\n",
      "Round 139/200 completed.\n",
      " Avg Local Loss: 0.0216\n",
      " Global Loss: 1.6664, Accuracy: 67.76%\n",
      "Round 140/200 starting...\n",
      "Round 140/200 completed.\n",
      " Avg Local Loss: 0.0070\n",
      " Global Loss: 1.6867, Accuracy: 67.47%\n",
      "Round 141/200 starting...\n",
      "Round 141/200 completed.\n",
      " Avg Local Loss: 0.0149\n",
      " Global Loss: 1.6750, Accuracy: 68.21%\n",
      "Round 142/200 starting...\n",
      "Round 142/200 completed.\n",
      " Avg Local Loss: 0.0101\n",
      " Global Loss: 1.6924, Accuracy: 67.70%\n",
      "Round 143/200 starting...\n",
      "Round 143/200 completed.\n",
      " Avg Local Loss: 0.0077\n",
      " Global Loss: 1.6395, Accuracy: 68.36%\n",
      "Round 144/200 starting...\n",
      "Round 144/200 completed.\n",
      " Avg Local Loss: 0.0071\n",
      " Global Loss: 1.7523, Accuracy: 67.01%\n",
      "Round 145/200 starting...\n",
      "Round 145/200 completed.\n",
      " Avg Local Loss: 0.0054\n",
      " Global Loss: 1.7386, Accuracy: 67.42%\n",
      "Round 146/200 starting...\n",
      "Round 146/200 completed.\n",
      " Avg Local Loss: 0.0064\n",
      " Global Loss: 1.7435, Accuracy: 67.67%\n",
      "Round 147/200 starting...\n",
      "Round 147/200 completed.\n",
      " Avg Local Loss: 0.0092\n",
      " Global Loss: 1.7544, Accuracy: 67.84%\n",
      "Round 148/200 starting...\n",
      "Round 148/200 completed.\n",
      " Avg Local Loss: 0.0092\n",
      " Global Loss: 1.7168, Accuracy: 67.99%\n",
      "Round 149/200 starting...\n",
      "Round 149/200 completed.\n",
      " Avg Local Loss: 0.0110\n",
      " Global Loss: 1.7163, Accuracy: 67.91%\n",
      "Round 150/200 starting...\n",
      "Round 150/200 completed.\n",
      " Avg Local Loss: 0.0258\n",
      " Global Loss: 1.6371, Accuracy: 68.28%\n",
      "Round 151/200 starting...\n",
      "Round 151/200 completed.\n",
      " Avg Local Loss: 0.0052\n",
      " Global Loss: 1.7045, Accuracy: 67.81%\n",
      "Round 152/200 starting...\n",
      "Round 152/200 completed.\n",
      " Avg Local Loss: 0.0101\n",
      " Global Loss: 1.7152, Accuracy: 68.23%\n",
      "Round 153/200 starting...\n",
      "Round 153/200 completed.\n",
      " Avg Local Loss: 0.0096\n",
      " Global Loss: 1.7658, Accuracy: 67.25%\n",
      "Round 154/200 starting...\n",
      "Round 154/200 completed.\n",
      " Avg Local Loss: 0.0074\n",
      " Global Loss: 1.7224, Accuracy: 68.05%\n",
      "Round 155/200 starting...\n",
      "Round 155/200 completed.\n",
      " Avg Local Loss: 0.0058\n",
      " Global Loss: 1.7361, Accuracy: 67.83%\n",
      "Round 156/200 starting...\n",
      "Round 156/200 completed.\n",
      " Avg Local Loss: 0.0062\n",
      " Global Loss: 1.7721, Accuracy: 67.53%\n",
      "Round 157/200 starting...\n",
      "Round 157/200 completed.\n",
      " Avg Local Loss: 0.0095\n",
      " Global Loss: 1.7756, Accuracy: 67.64%\n",
      "Round 158/200 starting...\n",
      "Round 158/200 completed.\n",
      " Avg Local Loss: 0.0196\n",
      " Global Loss: 1.7147, Accuracy: 68.26%\n",
      "Round 159/200 starting...\n",
      "Round 159/200 completed.\n",
      " Avg Local Loss: 0.0063\n",
      " Global Loss: 1.7453, Accuracy: 67.51%\n",
      "Round 160/200 starting...\n",
      "Round 160/200 completed.\n",
      " Avg Local Loss: 0.0050\n",
      " Global Loss: 1.7370, Accuracy: 68.05%\n",
      "Round 161/200 starting...\n",
      "Round 161/200 completed.\n",
      " Avg Local Loss: 0.0244\n",
      " Global Loss: 1.7675, Accuracy: 67.69%\n",
      "Round 162/200 starting...\n",
      "Round 162/200 completed.\n",
      " Avg Local Loss: 0.0055\n",
      " Global Loss: 1.8639, Accuracy: 66.98%\n",
      "Round 163/200 starting...\n",
      "Round 163/200 completed.\n",
      " Avg Local Loss: 0.0264\n",
      " Global Loss: 1.7207, Accuracy: 67.77%\n",
      "Round 164/200 starting...\n",
      "Round 164/200 completed.\n",
      " Avg Local Loss: 0.0050\n",
      " Global Loss: 1.7173, Accuracy: 68.26%\n",
      "Round 165/200 starting...\n",
      "Round 165/200 completed.\n",
      " Avg Local Loss: 0.0070\n",
      " Global Loss: 1.7733, Accuracy: 67.23%\n",
      "Round 166/200 starting...\n",
      "Round 166/200 completed.\n",
      " Avg Local Loss: 0.0041\n",
      " Global Loss: 1.7870, Accuracy: 67.68%\n",
      "Round 167/200 starting...\n",
      "Round 167/200 completed.\n",
      " Avg Local Loss: 0.0112\n",
      " Global Loss: 1.7272, Accuracy: 68.16%\n",
      "Round 168/200 starting...\n",
      "Round 168/200 completed.\n",
      " Avg Local Loss: 0.0059\n",
      " Global Loss: 1.7745, Accuracy: 68.44%\n",
      "Round 169/200 starting...\n",
      "Round 169/200 completed.\n",
      " Avg Local Loss: 0.0044\n",
      " Global Loss: 1.7520, Accuracy: 68.50%\n",
      "Round 170/200 starting...\n",
      "Round 170/200 completed.\n",
      " Avg Local Loss: 0.0115\n",
      " Global Loss: 1.8060, Accuracy: 67.72%\n",
      "Round 171/200 starting...\n",
      "Round 171/200 completed.\n",
      " Avg Local Loss: 0.0079\n",
      " Global Loss: 1.8517, Accuracy: 67.12%\n",
      "Round 172/200 starting...\n",
      "Round 172/200 completed.\n",
      " Avg Local Loss: 0.0030\n",
      " Global Loss: 1.8265, Accuracy: 67.56%\n",
      "Round 173/200 starting...\n",
      "Round 173/200 completed.\n",
      " Avg Local Loss: 0.0406\n",
      " Global Loss: 1.7053, Accuracy: 68.17%\n",
      "Round 174/200 starting...\n",
      "Round 174/200 completed.\n",
      " Avg Local Loss: 0.0112\n",
      " Global Loss: 1.6950, Accuracy: 68.32%\n",
      "Round 175/200 starting...\n",
      "Round 175/200 completed.\n",
      " Avg Local Loss: 0.0037\n",
      " Global Loss: 1.7423, Accuracy: 68.45%\n",
      "Round 176/200 starting...\n",
      "Round 176/200 completed.\n",
      " Avg Local Loss: 0.0044\n",
      " Global Loss: 1.8156, Accuracy: 67.51%\n",
      "Round 177/200 starting...\n",
      "Round 177/200 completed.\n",
      " Avg Local Loss: 0.0135\n",
      " Global Loss: 1.7837, Accuracy: 67.75%\n",
      "Round 178/200 starting...\n",
      "Round 178/200 completed.\n",
      " Avg Local Loss: 0.0048\n",
      " Global Loss: 1.8385, Accuracy: 67.18%\n",
      "Round 179/200 starting...\n",
      "Round 179/200 completed.\n",
      " Avg Local Loss: 0.0078\n",
      " Global Loss: 1.7327, Accuracy: 68.39%\n",
      "Round 180/200 starting...\n",
      "Round 180/200 completed.\n",
      " Avg Local Loss: 0.0068\n",
      " Global Loss: 1.9097, Accuracy: 66.65%\n",
      "Round 181/200 starting...\n",
      "Round 181/200 completed.\n",
      " Avg Local Loss: 0.0103\n",
      " Global Loss: 1.8438, Accuracy: 67.21%\n",
      "Round 182/200 starting...\n",
      "Round 182/200 completed.\n",
      " Avg Local Loss: 0.0127\n",
      " Global Loss: 1.7179, Accuracy: 68.12%\n",
      "Round 183/200 starting...\n",
      "Round 183/200 completed.\n",
      " Avg Local Loss: 0.0071\n",
      " Global Loss: 1.7602, Accuracy: 67.81%\n",
      "Round 184/200 starting...\n",
      "Round 184/200 completed.\n",
      " Avg Local Loss: 0.0104\n",
      " Global Loss: 1.7776, Accuracy: 67.85%\n",
      "Round 185/200 starting...\n",
      "Round 185/200 completed.\n",
      " Avg Local Loss: 0.0058\n",
      " Global Loss: 1.7666, Accuracy: 68.18%\n",
      "Round 186/200 starting...\n",
      "Round 186/200 completed.\n",
      " Avg Local Loss: 0.0193\n",
      " Global Loss: 1.7475, Accuracy: 68.11%\n",
      "Round 187/200 starting...\n",
      "Round 187/200 completed.\n",
      " Avg Local Loss: 0.0036\n",
      " Global Loss: 1.7750, Accuracy: 67.97%\n",
      "Round 188/200 starting...\n",
      "Round 188/200 completed.\n",
      " Avg Local Loss: 0.0041\n",
      " Global Loss: 1.7802, Accuracy: 68.22%\n",
      "Round 189/200 starting...\n",
      "Round 189/200 completed.\n",
      " Avg Local Loss: 0.0037\n",
      " Global Loss: 1.7811, Accuracy: 68.20%\n",
      "Round 190/200 starting...\n",
      "Round 190/200 completed.\n",
      " Avg Local Loss: 0.0031\n",
      " Global Loss: 1.8124, Accuracy: 68.19%\n",
      "Round 191/200 starting...\n",
      "Round 191/200 completed.\n",
      " Avg Local Loss: 0.0051\n",
      " Global Loss: 1.7991, Accuracy: 68.44%\n",
      "Round 192/200 starting...\n",
      "Round 192/200 completed.\n",
      " Avg Local Loss: 0.0031\n",
      " Global Loss: 1.8183, Accuracy: 68.26%\n",
      "Round 193/200 starting...\n",
      "Round 193/200 completed.\n",
      " Avg Local Loss: 0.0097\n",
      " Global Loss: 1.8301, Accuracy: 67.85%\n",
      "Round 194/200 starting...\n",
      "Round 194/200 completed.\n",
      " Avg Local Loss: 0.0055\n",
      " Global Loss: 1.8703, Accuracy: 66.98%\n",
      "Round 195/200 starting...\n",
      "Round 195/200 completed.\n",
      " Avg Local Loss: 0.0144\n",
      " Global Loss: 1.8231, Accuracy: 67.38%\n",
      "Round 196/200 starting...\n",
      "Round 196/200 completed.\n",
      " Avg Local Loss: 0.0041\n",
      " Global Loss: 1.8407, Accuracy: 67.86%\n",
      "Round 197/200 starting...\n",
      "Round 197/200 completed.\n",
      " Avg Local Loss: 0.0171\n",
      " Global Loss: 1.8811, Accuracy: 67.06%\n",
      "Round 198/200 starting...\n",
      "Round 198/200 completed.\n",
      " Avg Local Loss: 0.0039\n",
      " Global Loss: 1.8320, Accuracy: 67.98%\n",
      "Round 199/200 starting...\n",
      "Round 199/200 completed.\n",
      " Avg Local Loss: 0.0074\n",
      " Global Loss: 1.8090, Accuracy: 67.67%\n",
      "Round 200/200 starting...\n",
      "Round 200/200 completed.\n",
      " Avg Local Loss: 0.0079\n",
      " Global Loss: 1.8018, Accuracy: 68.13%\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate = 0.01\n",
    "momentum = 0\n",
    "mu = 0\n",
    "method = 'SCAFFOLD'\n",
    "\n",
    "federated_learning_with_scenario(server_class=Server, user_class=User, global_model_class=SimpleCNN, dataset=cifar10_train, test_loader=test_loader,\n",
    "        num_users=num_users,\n",
    "        rounds=rounds,\n",
    "        epochs=epochs,\n",
    "        fraction=fraction,\n",
    "        iid=iid,\n",
    "        lr=learning_rate,\n",
    "        alpha=alpha,\n",
    "        method=method,\n",
    "        momentum=momentum,\n",
    "        mu=mu,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (fed_env)",
   "language": "python",
   "name": "fed_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
